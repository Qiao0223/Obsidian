---
number headings: first-level 1, start-at 1, max 4, 1.1, auto, contents ^toc
---
黑马点评是一个以学习 Redis 为核心的实战项目，模拟类似大众点评的应用场景，涵盖了用户登录、商户查询、优惠券秒杀、探店笔记、好友关注、签到、UV统计等多个功能模块。该项目采用前后端分离架构，前端部署在 Nginx 上，后端基于 Spring Boot，使用 MyBatis-Plus、Redis 等技术栈。

# 1 项目架构与技术栈

- **架构模式**：前后端分离的单体应用。

- **后端技术**：

    - Spring Boot：快速构建项目框架。
    - MyBatis-Plus：简化数据库操作。
    - Redis：实现缓存、分布式锁、消息队列等功能。
    - Lombok、Hutool：提升开发效率。
    - Kafka：优化秒杀场景下的异步处理。

- **前端技术**：Vue.js，部署在 Nginx 上。

# 2 核心功能模块

## 2.1 用户登录与验证

- 用户通过手机号接收验证码进行登录。
- 验证码存储在 Redis 中，设置过期时间。
- 登录成功后，生成 Token 并将用户信息存储在 Redis 中，实现会话管理。

## 2.2 商户查询与缓存优化

- 商户信息缓存至 Redis，提升查询性能。
- 采用缓存穿透、缓存击穿、缓存雪崩等问题的解决策略，如缓存空对象、互斥锁、逻辑过期等。

## 2.3 优惠券秒杀系统

- 实现全局唯一 ID 生成器，避免订单重复。
- 使用 Redis 实现库存预减，防止超卖。
- 引入分布式锁（如 Redisson）确保并发安全。
- 通过消息队列（如 RabbitMQ）异步处理订单，提升系统吞吐量。

## 2.4 探店笔记与点赞功能

- 用户可以发布探店笔记，记录消费体验。
- 实现点赞功能，使用 Redis 的 Set 结构存储点赞用户，防止重复点赞。
- 基于 Sorted Set 实现点赞排行榜，展示热门笔记。

## 2.5 好友关注与 Feed 流

- 用户可以关注其他用户，形成社交关系。
- 实现共同关注、取消关注等功能。
- 通过 Redis 的 List 或 Sorted Set 实现 Feed 流，推送关注用户的最新动态。

## 2.6 用户签到与 UV 统计

- 使用 Redis 的 BitMap 实现用户签到功能，支持连续签到统计。
- 通过 HyperLogLog 实现 UV（独立访客）统计，节省内存空间。

# 3 用户登录

黑马点评的用户登录流程主要采用短信验证码（或邮件验证码）+手机号（或邮箱）的方式，结合Session/Redis存储以及拦截器进行登录状态校验。具体而言，当用户提交手机号或邮箱后，后台会生成一个随机验证码（通常为六位数字），并通过短信或邮件接口发送给用户，同时将验证码保存在Session 或 Redis 中。用户收到验证码后，将手机号/邮箱和验证码一起提交后台，后台从 Session 或 Redis 中取出原始验证码进行比对，验证通过后再根据手机号/邮箱查询或创建用户信息，并将用户信息封装为 DTO 存储到 Session 或以 `token` 形式存储到 Redis（Hash 结构中），然后将登录成功信息（如 `token`）返回给前端。后续用户访问时会在拦截器中，从 Cookie 中获取 `token` 或 SessionId，校验登录状态是否有效，若有效则放行并将用户信息放入 ThreadLocal，以便后续业务使用。整个流程还兼顾了分布式环境下 Session 共享的问题，并通过 DTO 机制对用户敏感信息进行脱敏处理。

## 3.1 发送验证码

### 3.1.1 验证码生成及存储

1. **生成六位随机验证码**  
    后端使用工具类随机生成一个六位数字验证码，并将该验证码与手机号（或邮箱）一一对应。生成方式通常是调用 Java 中的 `Random` 或其它验证码工具库来产生一个伪随机数。
    
2. **校验手机号/邮箱格式**
    - 当用户提交手机号时，后端会先调用正则表达式或专门的校验工具类验证手机号格式是否符合规范，若不合法则直接返回错误信息，提示“手机号格式错误”或“邮箱格式错误”。
    - 例如，检查手机号是否全为数字且长度为11位，或邮箱是否包含 `@` 且域名合法。
    
3. **存储验证码到 Session**
    - 初期的黑马点评实现基于传统 Servlet Session，将生成的验证码通过 `session.setAttribute("code", code)` 方式保存在 Session 中，Session 默认保存在服务器内存，由同一台 Tomcat 实例维护。
    - 若采用集群部署，Session 共享会存在不一致性问题，用户请求切换到不同节点时会导致 Session 丢失。
    
4. **升级至 Redis 存储**
    - 为了支持多机房或多实例部署，黑马点评后续将验证码存储迁移到 Redis 中，使用 `String` 类型，以 `login:code:[手机号]` 为 Key，Value 为验证码，设置 TTL（如 2 分钟或 120 秒），确保存储期间验证码有效。
    - 代码示例：
    - 这样可保证验证码在 Redis 集群中高效、快速地读取，且不同 Tomcat 实例共享同一 Redis 存储，解决了 Session 共享问题。
```
// 保存到 Redis 中，键为 login:code: + phone，过期时间 120 秒
stringRedisTemplate.opsForValue()
       .set(LOGIN_CODE_KEY + phone, code, LOGIN_CODE_TTL, TimeUnit.SECONDS);
```

### 3.1.2 发送渠道

- **短信发送**
    
    - 后端调用第三方短信服务（如阿里云短信、腾讯云短信、云片短信等）将验证码发送给用户手机。
    - 发送前可以在 Redis 中使用有序集合（ZSet）或 Set 对发送次数进行限制（如 5 分钟内不能重复发送；同一手机号一天发送次数上限），防止恶意刷码。
    
- **邮件发送**
    
    - 除短信验证码外，黑马点评也支持邮箱验证码模式，使用 JavaMail 或第三方邮件服务（如 Spring Boot 集成的 MailSender）发送验证码到用户邮箱。
    - 与短信模式类似，将验证码存储到 Redis 或 Session，再返回给前端提示“邮件已发送，请检查邮箱”。
    - 对邮件验证码亦可加入频率控制，如每5分钟只能发送一次；可以使用 Redis 的 ZSet 存储发送时间戳，检测最近发送记录。

## 3.2 验证码登录与注册

### 3.2.1 用户提交验证码、校验流程

1. **前端提交手机号/邮箱 + 验证码**
    - 用户在登录页面输入手机号（或邮箱）和收到的验证码，点击“登录/注册”。前端将数据封装为 `LoginFormDTO`（或类似 DTO），包含 `phone`（或 `email`）和 `code` 两个字段，通过 HTTP POST 提交到 `/user/login` 接口。
    
2. **后端校验验证码**
    - 后端先检查手机号/邮箱格式合法性，若不合格立即返回失败。
    - 从 Redis 中取值：
        若 `redisCode == null`，说明验证码过期或未发送，直接返回“验证码无效”；若 `!redisCode.equals(code)` 则返回“验证码错误”。
    - 若使用 Session 存储，则从 `HttpSession` 中通过 `session.getAttribute("code")` 取出，校验 `Object cacheCode` 与用户输入的 `code` 是否一致。
    
3. **注册或查询用户**
    - 验证通过后，根据手机号/邮箱在数据库中查询 `User` 实体（`select * from tb_user where phone = ?`）。若查询结果 `user == null`，则调用 `createUser(phone)` 创建新用户，设置 `phone`、`nickName`（可随机生成或默认 “用户+后四位”）、默认头像（随机或缺省），插入数据表。
    - 如果用户已存在，则直接获得该 `User` 对象。
    
4. **脱敏处理并封装为 DTO**
    - 为了避免将完整用户信息泄露给前端，黑马点评将 `User` 实体转换为 `UserDTO`，只保留必要的字段，如 `id`、`nickName`、`icon` 等；敏感字段如密码、手机号中间四位等会做脱敏处理。
    - 使用 `BeanUtil.copyProperties(user, UserDTO.class)` 等工具类快速拷贝到 DTO。
    
5. **保存登录状态**
    
    - **Session 模式**：将 `UserDTO` 对象 `session.setAttribute("user", userDTO)` 保存在 Session 中，以后基于 SessionId 自动识别登录状态。
    - **Redis 模式**：
        1. **生成 Token**：使用 `UUID.randomUUID().toString(true)`（去掉中划线）生成唯一 `token`，该 `token` 相当于会话标识符。
        2. **保存用户信息到 Redis**：将 `UserDTO` 转换为 `Map<String, String>` 后，通过 `stringRedisTemplate.opsForHash().putAll(LOGIN_USER_KEY + token, userMap)` 存储到 Redis Hash 中，并设置 TTL（如 30 分钟），用来维护登录状态。
        3. **返回 Token**：将生成的 `token` 放在 HTTP 响应结果中，前端通常将 `token` 存入 Cookie（如 `user_token`）或 LocalStorage，以便后续请求携带。
    
6. **返回登录结果给前端**
    - 返回 JSON 格式，例如 `{ "code": 0, "msg": "登录成功", "token": "xxxxx" }`，其中 `token` 在 Session 模式下会直接交给前端保管 Cookie；在 Redis 模式下前端需要将该 `token` 放入 `Authorization` Header 或 Cookie 中。

## 3.3 登录状态校验与拦截

### 3.3.1 基于 Session 的拦截

1. **拦截器配置**
    - 在 Spring Boot 中自定义 `LoginInterceptor` 并注册到 `WebMvcConfigurer` 中，对所有需要登录保护的 URL 添加拦截规则（`addPathPatterns("/api/user/**")` 等），排除 `/user/login`、`/user/code` 等无需登录接口。[blog.51cto.com](https://blog.51cto.com/u_16099276/10067178?utm_source=chatgpt.com)[blog.csdn.net](https://blog.csdn.net/weixin_65935065/article/details/132124345?utm_source=chatgpt.com)
    
2. **校验 Session 中是否存在用户信息**
    - 在 `preHandle` 方法中，通过 `HttpServletRequest.getSession(false)` 获取当前 Session，对比 `session != null && session.getAttribute("user") != null`，若不存在则返回 HTTP 401（未登录）或跳转到登录页面；若存在则将 `UserDTO` 放入 `ThreadLocal`（或一些上下文），方便后续 Controller 或 Service 获取当前登录用户。[blog.csdn.net](https://blog.csdn.net/weixin_65935065/article/details/132124345?utm_source=chatgpt.com)[blog.51cto.com](https://blog.51cto.com/u_16099276/10067178?utm_source=chatgpt.com)
        
3. **ThreadLocal 线程隔离**
    - 由于一个请求可能会被不同线程处理，为保证每个请求线程都能获取到正确的用户信息，拦截器会将 `UserDTO` 存入 `UserHolder.setUser(userDTO)`（`ThreadLocal` 实例），并在请求处理完成后清理线程中的 `ThreadLocal`，防止内存泄露。
    

### 3.3.2 基于 Redis Token 的拦截

1. **获取 Token 并校验**
    - 拦截器从 `HttpServletRequest` 中取出前端传递的 `token`（可以是 Header `Authorization: Bearer [token]` 或 Cookie 等），若 `token == null`，直接返回未登录。
    - 使用 `stringRedisTemplate.opsForHash().entries(LOGIN_USER_KEY + token)` 从 Redis 中取出对应的用户 Hash，若结果为空或 TTL 过期，则认为登录失效，需要重新登录；若存在则获取用户信息并封装为 `UserDTO`。
    
2. **续期**
    - 为防止用户长时间在线后频繁操作导致 Session 过期，拦截器会自动在每次请求时，将 Redis 中该 Token 的 TTL 再次设置为初始值（如 30 分钟），实现“登录延迟”（Sliding Expiration）。
    
3. **将 `UserDTO` 放入 ThreadLocal**
    - 与 Session 模式类似，成功校验后将 `UserDTO` 存入 `ThreadLocal`，以便后续业务层直接调用 `UserHolder.getUser()` 获取当前登录用户。请求结束后在 `afterCompletion` 中清除。

## 3.4 验证码防刷设计与限流

### 3.4.1 单机 Session 存储下的限流

1. **5 分钟内禁止重复发送（`limit:onelevel:[phone]`）**
    - 在 Redis 中使用 Set 结构存储已经发送过验证码的手机号，到达 5 分钟时通过定时任务或过期策略清除 Set 中对应手机号，避免同一手机号在短时间内多次请求验证码。
    
2. **更细粒度的间隔限制**
    - 也可以使用有序集合（ZSet）将发送时间戳记录在集合中，每次发送前检查最近一个发送时间是否距离当前时间 < 60 秒，若过于频繁则拒绝。
    
3. **每日发送上限**
    - 可以在 Redis 中针对同一手机号维护计数器（如 `limit:daily:[phone]`），每天零点自动重置；当计数器大于设定值（如 10 次）时，禁止当天继续发送。
    

### 3.4.2 分布式环境下的限流

1. **基于 Redis 的全局限流**
    - 在集群环境下，所有实例共用同一 Redis，通过原子命令 `INCR`、`EXPIRE` 实现全局限流，保证无论请求落在哪台服务器，限流策略都一致。
    
2. **使用令牌桶或漏桶算法**
    - 也可整合 Redis + Lua 脚本，采用令牌桶或漏桶算法，为更精细的限速提供保障，防止分布式环境下在高并发情况下出现“雪崩”或“击穿”问题。

## 3.5 安全与优化

### 3.5.1 防止验证码枚举与暴力破解

1. **验证码有效期短**
    - 将验证码在 Redis 中 TTL 设置为较短时间（如 120 秒），过期后自动删除，避免长时间被猜解。
    
2. **错误次数限制**
    - 在 Redis 中维护一个“校验错误计数”键，如 `login:fail:[phone]`，当同一手机号连续 5 次输入错误验证码后，临时屏蔽 10 分钟，锁定登录，防止暴力破解。
    
3. **验证码字符复杂度**
    - 可以将六位数字升级为包含字母的混合验证码，增加破解难度。

### 3.5.2 隐藏敏感信息与 DTO 设计

1. **去除敏感字段**
    - `User` 实体中可能包含密码（或 OpenID）、手机号、身份证号等敏感字段，使用 `UserDTO` 仅保留 `id`、`nickName`、`icon`、`gender` 等非敏感字段返回给前端。
    
2. **使用 BeanUtil 进行深拷贝**
    - 利用 `BeanUtil.copyProperties(user, UserDTO.class)` 或 `BeanUtils`、`ModelMapper` 等工具快速拷贝属性，并对敏感字段进行手动设 `null` 或脱敏处理。
    
3. **HttpOnly & Secure Cookie**
    - 若使用 Cookie 存储 Token，设置 `HttpOnly` 标记，防止前端 JavaScript 读取；在 HTTPS 环境下同时设置 `Secure`，防止 Token 在明文 HTTP 时泄露。

### 3.5.3 MVC 结构与分层

#### 3.5.3.1 Controller 层
负责接收前端请求，将参数封装到 `LoginFormDTO`（包含 `phone`、`code` 等），调用 Service 完成业务逻辑。
```
@PostMapping("/login")
public Result login(@RequestBody LoginFormDTO loginForm) {
    return userService.login(loginForm);
}
```

#### 3.5.3.2 Service 层
负责核心业务逻辑：校验手机号/邮箱格式、从 Redis/Session 获取验证码、查询/创建用户、生成 Token、保存到 Redis/Session、返回 DTO 等。
```
public Result login(LoginFormDTO loginForm) {
    // 校验手机号
    if (RegexUtils.isPhoneInvalid(loginForm.getPhone())) {
        return Result.fail("手机号码格式错误");
    }
    // 从 Redis 获取验证码
    String redisCode = stringRedisTemplate.opsForValue().get(LOGIN_CODE_KEY + phone);
    if (redisCode == null || !redisCode.equals(loginForm.getCode())) {
        return Result.fail("验证码错误");
    }
    // 查询或创建用户
    User user = query().eq("phone", phone).one();
    if (user == null) {
        user = createUser(phone);
    }
    // 脱敏并转换 DTO
    UserDTO userDTO = BeanUtil.copyProperties(user, UserDTO.class);
    // 生成 Token 并保存到 Redis
    String token = UUID.randomUUID().toString(true);
    Map<String, Object> userMap = BeanUtil.beanToMap(userDTO);
    stringRedisTemplate.opsForHash().putAll(LOGIN_USER_KEY + token, userMap);
    stringRedisTemplate.expire(LOGIN_USER_KEY + token, LOGIN_USER_TTL, TimeUnit.MINUTES);
    return Result.ok(token);
}
```

#### 3.5.3.3 Interceptor 层
负责对需要登录的接口进行拦截，从 Redis 或 Session 校验登录状态，将 `UserDTO` 放入 `UserHolder`（ThreadLocal），并在请求完成后清理。

#### 3.5.3.4 DAO 层
使用 MyBatis-Plus 或 MyBatis 操作数据库，对于新用户使用 `insert`，以及通过 `query().eq("phone", phone).one()` 查询。

## 3.6 典型代码示例

### 3.6.1 生成并发送验证码

```
/**
 * 发送短信验证码
 */
@PostMapping("/sendCode")
public Result sendCode(@RequestParam("phone") String phone, HttpSession session) {
    // 1. 校验手机号格式
    if (!RegexUtils.isPhoneValid(phone)) {
        return Result.fail("手机号格式错误");
    }
    // 2. 生成随机验证码
    String code = RandomUtil.randomNumbers(6);
    // 3. 将验证码存入 Redis，并设置 TTL
    stringRedisTemplate.opsForValue()
        .set(LOGIN_CODE_KEY + phone, code, LOGIN_CODE_TTL, TimeUnit.MINUTES);
    // 4. 调用短信服务发送验证码
    smsService.sendSms(phone, code);
    return Result.ok();
}
```
捕获并抛出可能的短信发送异常，同时在 Redis 中进行限流控制（如：同一手机号 1 分钟内只能发送一次）。

### 3.6.2 登录逻辑
```
/**
 * 短信验证码登录
 */
@PostMapping("/login")
public Result login(@RequestBody LoginFormDTO loginForm, HttpSession session) {
    // 1. 校验手机号格式
    String phone = loginForm.getPhone();
    if (RegexUtils.isPhoneInvalid(phone)) {
        return Result.fail("手机号码格式错误！");
    }
    // 2. 从 Redis 获取验证码并校验
    String redisCode = stringRedisTemplate.opsForValue().get(LOGIN_CODE_KEY + phone);
    if (redisCode == null || !redisCode.equals(loginForm.getCode())) {
        return Result.fail("验证码错误！");
    }
    // 3. 查询用户；若不存在则创建
    User user = userService.query().eq("phone", phone).one();
    if (user == null) {
        user = userService.createUserWithPhone(phone);
    }
    // 4. 脱敏并转换 DTO
    UserDTO userDTO = BeanUtil.copyProperties(user, UserDTO.class);
    // 5. 生成 Token 并保存到 Redis
    String token = UUID.randomUUID().toString(true);
    Map<String, Object> userMap = BeanUtil.beanToMap(userDTO, new HashMap<>(),
        CopyOptions.create().setIgnoreNullValue(true)
                           .setFieldValueEditor((fieldName, fieldValue) -> fieldValue.toString()));
    stringRedisTemplate.opsForHash().putAll(LOGIN_USER_KEY + token, userMap);
    // 6. 设置登录状态过期时间
    stringRedisTemplate.expire(LOGIN_USER_KEY + token, LOGIN_USER_TTL, TimeUnit.MINUTES);
    return Result.ok(token);
}
```
方法 `createUserWithPhone` 中会初始化 `User` 实体，设置默认 `nickName`、`avatar` 等属性，并保存到数据库。

### 3.6.3 拦截器示例

```
@Component
public class LoginInterceptor implements HandlerInterceptor {
    @Autowired
    private StringRedisTemplate stringRedisTemplate;

    @Override
    public boolean preHandle(HttpServletRequest request,
                             HttpServletResponse response,
                             Object handler) throws Exception {
        // 1. 获取 Token
        String token = request.getHeader("Authorization");
        if (StrUtil.isBlank(token)) {
            response.setStatus(HttpStatus.UNAUTHORIZED.value());
            return false;
        }
        // 2. 从 Redis 获取用户数据
        Map<Object, Object> userMap = stringRedisTemplate.opsForHash()
                                     .entries(LOGIN_USER_KEY + token);
        if (userMap.isEmpty()) {
            response.setStatus(HttpStatus.UNAUTHORIZED.value());
            return false;
        }
        // 3. 将 Map 转回 UserDTO 并存入 ThreadLocal
        UserDTO userDTO = BeanUtil.fillBeanWithMap(userMap, new UserDTO(), true);
        UserHolder.saveUser(userDTO);
        // 4. 刷新过期时间（续期）
        stringRedisTemplate.expire(LOGIN_USER_KEY + token, LOGIN_USER_TTL, TimeUnit.MINUTES);
        return true;
    }

    @Override
    public void afterCompletion(HttpServletRequest request,
                                HttpServletResponse response,
                                Object handler,
                                Exception ex) throws Exception {
        // 清理 ThreadLocal
        UserHolder.removeUser();
    }
}
```
在 `WebConfig` 中注册拦截器，排除 `/sendCode`、`/login` 等无需登录接口。

# 4 商户查询与缓存优化

黑马点评的商户查询与缓存优化主要基于**Redis**实现高性能缓存，辅以**双写一致性**、**空值填充**、**互斥锁/逻辑过期**等策略来解决**缓存穿透**、**缓存击穿**和**缓存雪崩**等常见问题，并可选用**Caffeine**在应用层配合 Redis 构建二级缓存，进一步提升查询效率与可用性。整体流程中，当接收到商户 ID 查询请求时，系统首先从 Redis 缓存中读取数据，若存在则直接返回；若缓存未命中，则通过分布式锁或逻辑过期机制避免热点重建压力，从数据库加载后写回缓存，同时设置合理的 TTL 或逻辑过期时间。为了防止数据库中不存在的商户频繁请求导致缓存穿透，系统会对不存在的商户在 Redis 中写入空对象并短期过期；而对于可能集中在同一时刻大量缓存失效导致的缓存雪崩，系统会在设置 TTL 时加入随机抖动，并可实用本地 Caffeine 缓存做一级缓存，以降低对 Redis 的瞬时并发访问压力。最后，通过合理的缓存更新策略（如先写库再删缓存）确保商户信息更新时的双写一致性，保证系统在高并发环境下依旧具备稳定的响应能力和数据准确性。

## 4.1 基础缓存模型与双写一致

### 4.1.1 查询时的缓存读取逻辑
- **优先从 Redis 缓存读取商户信息**  
    在 `ShopService.queryById(id)` 方法中，系统首先调用 Redis 客户端尝试获取 Key 为 `shop:[id]` 的缓存数据，如果命中则直接将反序列化后的 `Shop` 对象返回给调用方，并结束整个查询流程。
- **缓存未命中则查询数据库并回写缓存**  
    若 Redis 中不存在对应 Key 或已过期，则执行数据库 `SELECT * FROM shop WHERE id = ?` 查询，将查询结果转为 `Shop` 对象后，再将其序列化并写入 Redis 缓存，同时设置 TTL（如 30 分钟）。这样能让后续相同 ID 的请求直接读取缓存，从而极大地减少数据库压力。

### 4.1.2 更新时的缓存双写策略
- **先更新数据库，再删除缓存**  
    在对商户信息进行更新操作时，首先执行 `UPDATE shop SET ... WHERE id = ?` 更新数据库；之后立即调用 `redisTemplate.delete("shop:" + id)` 删除缓存，使得下次查询时能够重新从数据库加载最新的数据并回写缓存，以保证读写一致性。
- **保障原子性与一致性**  
    为了避免在并发场景下出现“先删后写”或“先写后删”引起的脏数据，通常要求在业务逻辑中将数据库更新与缓存删除封装在同一个事务范围内执行，或通过使用分布式事务/消息队列等方式确保顺序与可靠性

## 4.2 解决缓存穿透

- **当数据库查询结果为 null 时，向缓存写入空对象**  
    在 `ShopService.queryById(id)` 查询流程中，如果数据库中不存在对应 ID 的商户，系统会在 Redis 中写入一个空值（例如空的 JSON 或者标记对象），并设置较短的 TTL（如 1 分钟）。将空值写入缓存后，后续对同一不存在商户的请求将直接从缓存命中空值并快速返回，避免打到数据库。
- **短 TTL 限制对空值的过期时间**  
    对空值设置较短的过期时间能够平衡防穿透效果与缓存空间利用率，防止空值在缓存中长期占用内存。

## 4.3 解决缓存击穿

### 4.3.1 互斥锁（Mutex）方案

- **获取分布式锁后加载数据库**  
    当 `queryById` 发现缓存未命中且未读到空值时，先尝试使用如 `SETNX` 或 Redisson 等方式加一个分布式锁（Key 形如 `lock:shop:[id]`）。只有成功获取锁的线程才会去数据库加载并写缓存，其他线程则进入自旋等待或短暂休眠后重试，从而避免 N 个线程同时查询数据库。
    
- **加载完成后释放锁与写入缓存**  
    获取锁的线程完成数据库查询后，将结果写入 Redis 缓存并设置合理 TTL，然后释放锁。此时其他等待线程再次尝试读取缓存，得到缓存后方可结束，避免重复查询数据库。
```
public Shop queryById(Long id) {
    // 1. 查询缓存
    Shop shop = redisTemplate.opsForValue().get("shop:" + id);
    if (shop != null) {
        return shop;
    }
    // 2. 缓存未命中，尝试获取锁
    String lockKey = "lock:shop:" + id;
    boolean acquired = tryLock(lockKey, timeout);
    if (acquired) {
        try {
            // Double check 获取锁后再次验证缓存，防止重复加载
            shop = redisTemplate.opsForValue().get("shop:" + id);
            if (shop != null) {
                return shop;
            }
            // 3. 缓存仍未命中，查询数据库
            shop = shopMapper.selectById(id);
            if (shop == null) {
                // 写入空值防穿透
                redisTemplate.opsForValue().set("shop:" + id, "", 60, TimeUnit.SECONDS);
                return null;
            }
            // 4. 将查询结果写入缓存
            redisTemplate.opsForValue().set("shop:" + id, shop, 30, TimeUnit.MINUTES);
            return shop;
        } finally {
            // 5. 释放锁
            unlock(lockKey);
        }
    } else {
        // 获取锁失败，短暂等待后重试
        Thread.sleep(50);
        return queryById(id);
    }
}
```

### 4.3.2 逻辑过期方案

- **在缓存中同时存储数据和过期时间戳**  
    与直接依赖 Redis TTL 不同，逻辑过期通常会把 `ShopData` 与 `expireTime` 一同封装到一个对象中存储在 Redis，如：
    `{   "data": {/* Shop 对象字段 */},   "expireTime": "2025-06-04T08:00:00" }`
    缓存中只设置一个很长的 Redis TTL（例如 1 天），由逻辑过期字段控制热度。
    
- **访问时检查逻辑过期时间**  
    当用户请求查询时，先从 Redis 反序列化该封装对象，判断 `expireTime` 是否在当前时间之后，如果尚未过期，则直接返回 `data`；如果已经过期，则让第一个检测到过期的线程异步刷新数据库并更新缓存（利用互斥锁或单线程池），而主线程仍可直接返回旧数据以保证高可用。这样既保证了缓存并不会瞬间全部失效，又能及时异步更新数据。

## 4.4 解决缓存雪崩

### 4.4.1 随机 TTL
在给 Redis 写入商户缓存时，不要将所有 Key 都统一设置为一个固定的过期时间，而是对 TTL 增加一个随机值，例如 `base + random(0~300)` 秒，使得缓存过期时钟分散，避免集中过期造成的并发打库。

### 4.4.2 使用本地 Caffeine 构建二级缓存
- 在应用层内存中集成 Caffeine作为一级缓存，将热点商户数据先缓存在本地内存中，当本地缓存未命中时再访问 Redis；这样可以进一步减轻 Redis 压力。
- 以 Caffeine 和 Redis 组合的双重缓存可以分为：
    1. **Caffeine（一级）**：超短 TTL（如 1 分钟），内存读取速度极快；
    2. **Redis（二级）**：稍长 TTL（如 30 分钟+随机抖动），跨进程共享，支持分布式。
在 `ShopServiceImpl.queryById` 中增加本地缓存查找逻辑：
```
public Shop queryById(Long id) {
    // 1. 本地 Caffeine 缓存读取
    Shop shop = caffeineCache.getIfPresent(id);
    if (shop != null) {
        return shop;
    }
    // 2. 二级 Redis 缓存读取（参照前面流程）
    shop = redisTemplate.opsForValue().get("shop:" + id);
    if (shop != null) {
        // 3. 命中后回写到本地 Caffeine 缓存，并返回
        caffeineCache.put(id, shop);
        return shop;
    }
    // …（后续数据库加载/互斥锁/逻辑过期等处理）
}
```
通过这种“先本地再 Redis，再数据库”的三级查找链路，可显著降低 Redis 与数据库在高并发场景下的压力，同时借助 Caffeine 本地缓存的高命中率提升性能。

## 4.5 具体实现要点与最佳实践

### 4.5.1 Redis Key 设计与序列化

- **Key 命名规范**  
    建议使用前缀 + 对象名 + ID 的方式，如 `shop:123`，方便定位与清理缓存。
    
- **序列化方式**
    - 对于简单数据，可使用 JSON 序列化（如 Jackson `ObjectMapper`）存储到 Redis；或者使用 Spring Data Redis 默认的 `JdkSerializationRedisSerializer`。
    - 对于性能敏感场景，可以考虑使用二进制序列化（如 Protostuff、Kryo），进一步减少网络与存储开销。

### 4.5.2 分布式锁的选择与实现

- **基于 Redis 的 `SETNX` + 过期时间**
    - 最简单的分布式锁：调用 `SET resource_name my_random_value NX PX 30000`，确保只有一个线程能成功设置锁；使用随机值避免误删问题；加锁失败后可通过自旋/延迟重试的方式获取。
    
- **使用 Redisson 简化锁管理**
    - Redisson 库封装了分布式锁功能，使得获取锁、续期和释放更安全便捷，无需手动管理随机值、心跳与 Lua 脚本。
```
RLock lock = redissonClient.getLock("lock:shop:" + id);
boolean acquired = lock.tryLock(100, 10, TimeUnit.SECONDS);
if (acquired) {
    try {
        // 执行业务
    } finally {
        lock.unlock();
    }
}
```
Redisson 默认对锁进行 WatchDog 扩展，避免因业务执行时间稍长导致锁过期后被误释放。

## 4.6 源码示例摘录

### 4.6.1 `ShopServiceImpl.queryById` 核心代码
该代码实现了**缓存穿透防护**（空值写入）、**缓存击穿防护**（Redisson 分布式锁 + double-check）、**缓存雪崩防护**（随机 TTL）以及**数据库更新后删除缓存保证双写一致性**。
```
@Service
public class ShopServiceImpl implements IShopService {

    @Autowired
    private StringRedisTemplate redisTemplate;

    @Autowired
    private ShopMapper shopMapper;

    @Autowired
    private RedissonClient redissonClient;

    // 查询商户并实现缓存穿透、缓存击穿、逻辑过期等
    public Shop queryById(Long id) {
        // 1. 缓存读取
        String shopJson = redisTemplate.opsForValue().get("shop:" + id);
        if (StrUtil.isNotBlank(shopJson)) {
            return JSONUtil.toBean(shopJson, Shop.class);
        }
        // 2. 判断是否为缓存空值，防止穿透
        if (shopJson != null && shopJson.equals("")) {
            return null;
        }
        // 3. 缓存未命中，获取分布式锁
        RLock lock = redissonClient.getLock("lock:shop:" + id);
        boolean isLock = false;
        try {
            isLock = lock.tryLock(3, 10, TimeUnit.SECONDS);
            if (isLock) {
                // 4. double-check 再次读取缓存
                shopJson = redisTemplate.opsForValue().get("shop:" + id);
                if (StrUtil.isNotBlank(shopJson)) {
                    return JSONUtil.toBean(shopJson, Shop.class);
                }
                // 5. 缓存仍未命中，查询数据库
                Shop shop = shopMapper.selectById(id);
                if (shop == null) {
                    // 6. 写入空值并设置短期过期
                    redisTemplate.opsForValue().set("shop:" + id, "", 60, TimeUnit.SECONDS);
                    return null;
                }
                // 7. 写入缓存并设置随机TTL，防止雪崩
                long expireTime = 1800 + RandomUtil.randomLong(300);
                redisTemplate.opsForValue().set("shop:" + id,
                    JSONUtil.toJsonStr(shop), expireTime, TimeUnit.SECONDS);
                return shop;
            } else {
                // 8. 未获取锁，短暂等待后重试
                Thread.sleep(50);
                return queryById(id);
            }
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        } finally {
            if (isLock) {
                lock.unlock();
            }
        }
    }

    @Transactional
    public void updateShop(Shop shop) {
        // 1. 更新数据库
        shopMapper.updateById(shop);
        // 2. 删除缓存，保证下次查询加载最新数据
        redisTemplate.delete("shop:" + shop.getId());
    }
}
```

### 4.6.2 二级缓存示例
该示例在**本地 Caffeine 缓存**基础上，再访问 **Redis 二级缓存**，最后才打数据库，能够将热点数据“沉淀”到应用内存，降低 Redis 请求压力。
```
@Configuration
public class CacheConfig {

    @Bean
    public Cache<Object, Object> caffeineCache() {
        return Caffeine.newBuilder()
                .initialCapacity(100)
                .maximumSize(1000)
                .expireAfterWrite(1, TimeUnit.MINUTES)
                .build();
    }
}

@Service
public class ShopServiceImpl implements IShopService {

    @Autowired
    private Cache<Long, Shop> caffeineCache;

    @Autowired
    private StringRedisTemplate redisTemplate;

    @Autowired
    private ShopMapper shopMapper;

    public Shop queryById(Long id) {
        // 1. 先查 Caffeine 本地缓存
        Shop shop = caffeineCache.getIfPresent(id);
        if (shop != null) {
            return shop;
        }
        // 2. 查 Redis 缓存
        String shopJson = redisTemplate.opsForValue().get("shop:" + id);
        if (StrUtil.isNotBlank(shopJson)) {
            shop = JSONUtil.toBean(shopJson, Shop.class);
            // 3. 回写 Caffeine 缓存
            caffeineCache.put(id, shop);
            return shop;
        }
        // 4. 缓存未命中，走互斥锁加载 DB 并回写双缓存
        shop = loadShopWithMutex(id);
        if (shop != null) {
            caffeineCache.put(id, shop);
        }
        return shop;
    }

    private Shop loadShopWithMutex(Long id) {
        // 同前面的获取分布式锁逻辑，用于从数据库加载，
        // 写入 Redis，并返回 Shop 对象
        // ...
        return shop;
    }
}
```

## 4.7 典型问题与可选方案

- **缓存穿透的替代方案**
    - 除空值填充外，还可结合**布隆过滤器**（Bloom Filter）预先存储所有合法商户 ID，当请求走向 Redis 之前先查询布隆过滤器，若布隆过滤器判定该 ID 不存在，则直接返回 null，从而避免多余的缓存/数据库读取。
    
- **缓存雪崩的分布式限流**
    - 当大规模缓存同时失效时，可先对查询请求进行限流或降级处理（如返回默认值、直接拒绝），并启动**后台预热**或**异步批量加载**策略，将热点商户提前加载到缓存。
    
- **一致性哈希与分片缓存**
    - 对于超大规模商户数据，可通过 Redis Cluster 或一致性哈希将不同 ID 范围分片到不同节点，避免单个 Redis 实例成为瓶颈；同时结合本地缓存能够更好地支撑千万级 QPS。
    
- **读写分离与异步更新**
    - 将数据库架构设计为主从复制，查询走从库，写走主库；更新业务则在主库写入后异步同步到从库，并通过消息队列异步删除缓存，以缩短缓存失效到重建的时间窗口。

## 4.8 流程图

![[黑马点评商户查询.svg]]

# 5 优惠券秒杀

黑马点评的优惠券秒杀功能主要通过**Redis**与**消息队列**协同实现，兼顾高并发下的库存一致性、一人一单限制和全局唯一订单ID生成。系统先在数据库中维护优惠券和秒杀券的基础信息（包括库存、开始与结束时间），然后利用**Redis 原子递减**或**Lua 脚本**保证库存操作的原子性，从而避免库存超卖（超卖问题）。在接收到秒杀请求后，通过**Redis 分布式锁**或使用**乐观锁**校验库存，判断秒杀时间窗口是否生效，以及检查当前用户是否已经下过单，以保证“一人一单”逻辑。为了进一步提高系统的吞吐量，核心下单逻辑通常通过**异步消息队列（RabbitMQ）**脱离请求线程，当 Redis 校验通过后，将下单请求封装成消息投递到队列，由消费者异步执行数据库插入操作和库存扣减，从而大幅降低接口响应时间并避免瞬时数据库压力激增。此外，黑马点评还通过**Redis 实现全局唯一ID生成**，避免了数据库自增ID带来的重复与性能瓶颈问题。总之，该秒杀机制融合了 Redis 本地高效的原子操作与分布式锁、消息队列异步处理等多种技术手段，确保在高并发场景下既能快速响应用户请求，也能保障库存与订单数据的一致性与安全性。

## 5.1 数据库设计与核心表结构

### 5.1.1 优惠券与秒杀券表

1. **基础优惠券表（`tb_voucher`）**  
    存储优惠券的基本属性，包括优惠金额、使用规则、对应店铺ID、逻辑删除标志等字段，普通优惠券无需限量，用户可以随时领取。
    
2. **秒杀券表（`tb_seckill_voucher`）**  
    特价秒杀券单独存储秒杀信息，包括：
    
    - `voucher_id`：关联 `tb_voucher.id`
    - `stock`：秒杀库存
    - `begin_time`、`end_time`：秒杀开始与结束时间，用于判断当前请求是否在秒杀时间窗口内
    - `create_time`、`update_time`：记录秒杀券的创建与更新时间  
        如示例，秒杀券表定义如下：
```
CREATE TABLE tb_seckill_voucher (
    voucher_id BIGINT PRIMARY KEY,
    stock INT NOT NULL,
    begin_time DATETIME NOT NULL,
    end_time DATETIME NOT NULL,
    create_time DATETIME,
    update_time DATETIME
);
```

### 5.1.2 秒杀订单表

秒杀成功后，需要将订单存入 `tb_voucher_order` 表，字段包括：

- `id`：全局唯一订单ID（由 Redis 生成）
- `user_id`：发起秒杀的用户ID
- `voucher_id`：秒杀券ID
- `shop_id`：对应的店铺ID（也可冗余写入）
- `create_time`：创建时间戳
- `status`：订单状态，如未支付、已完成等  
    表结构示例：
```
CREATE TABLE tb_voucher_order (
    id BIGINT PRIMARY KEY,
    user_id BIGINT NOT NULL,
    voucher_id BIGINT NOT NULL,
    shop_id BIGINT NOT NULL,
    create_time DATETIME DEFAULT CURRENT_TIMESTAMP,
    status INT DEFAULT 0
);
```

## 5.2 全局唯一ID生成

秒杀系统需要在高并发场景下生成唯一订单ID，避免使用数据库自增ID带来的性能瓶颈与可预测性。

1. **ID 组成**  
    黑马点评项目中引用了基于 Redis 的全局ID生成器（`RedisIdWorker`），其ID由三部分组成：
    - **符号位（1 bit）**：固定为0，保证生成的ID为正数
    - **时间戳（31 bits）**：从某个固定开始时间（如 `1640995200L`）到当前的秒数差值，可支持持续约69年的时间范围
    - **序列号（32 bits）**：当天的自增序列号，使用 `StringRedisTemplate.opsForValue().increment("icr:" + keyPrefix + ":" + date)` 进行原子自增，以秒为单位生成当天序列号，序列号范围可达 `2^32`  

2. **示例代码**
```
@Component
public class RedisIdWorker {
    private static final long BEGIN_TIMESTAMP = 1640995200L;
    private static final int COUNT_BITS = 32;
    private StringRedisTemplate stringRedisTemplate;
    public RedisIdWorker(StringRedisTemplate stringRedisTemplate) {
        this.stringRedisTemplate = stringRedisTemplate;
    }
    public long nextId(String keyPrefix) {
        // 1. 获取当前的秒级时间戳
        long nowSecond = LocalDateTime.now().toEpochSecond(ZoneOffset.UTC);
        long timestamp = nowSecond - BEGIN_TIMESTAMP;
        // 2. 生成当天序列号
        String date = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy:MM:dd"));
        long count = stringRedisTemplate.opsForValue().increment("icr:" + keyPrefix + ":" + date);
        // 3. 拼接：timestamp 左移 32 位 | count
        return (timestamp << COUNT_BITS) | count;
    }
}
```

3. **调用方式**  
    秒杀下单时，系统调用 `redisIdWorker.nextId("order")` 生成一个全局唯一的订单ID，并将其作为 `tb_voucher_order.id` 字段插入数据库，保证分布式环境下的ID不重复且高效率生成。

## 5.3 秒杀券发布与预热

1. **新增秒杀券接口**  
    在 `VoucherController` 中提供一个 `/vouchers/seckill` POST 接口，接受一个带有 `stock`、`beginTime`、`endTime` 等字段的 `Voucher` 对象，然后调用 `voucherService.addSeckillVoucher(voucher)` 将秒杀券信息保存到 `tb_voucher` 和 `tb_seckill_voucher` 两张表中。例如：
```
@PostMapping("/vouchers/seckill")
public Result addSeckillVoucher(@RequestBody Voucher voucher) {
    voucherService.addSeckillVoucher(voucher);
    return Result.ok(voucher.getId());
}
```
    在 `VoucherServiceImpl` 中，先将基础优惠券插入 `tb_voucher`，再将秒杀信息插入 `tb_seckill_voucher`，并用事务保证两表一致性。

2. **数据预热到 Redis（可选）**  
    为提高秒杀时的查询效率，通常在秒杀开始前，将秒杀券的库存 `stock` 和限量信息预热到 Redis 中，例如将 `stock` 值存入 `Redis Key：seckill:stock:[voucherId]`，方便后续秒杀时直接在 Redis 中进行原子操作，而无需再查询数据库，从而减少数据库读量并加快响应。
```
// 示例：秒杀开始前预热库存
public void preloadSeckillVoucher(Long voucherId) {
    SeckillVoucher sv = seckillVoucherMapper.selectById(voucherId);
    stringRedisTemplate.opsForValue().set("seckill:stock:" + voucherId, 
        sv.getStock().toString());
    // 也可以将秒杀开始时间和结束时间缓存，以便快速校验
    stringRedisTemplate.opsForValue().set("seckill:begin:" + voucherId, sv.getBeginTime().toString());
    stringRedisTemplate.opsForValue().set("seckill:end:" + voucherId, sv.getEndTime().toString());
}
```

## 5.4 秒杀下单流程

秒杀下单核心流程包括：**校验秒杀时间窗口**、**判断库存是否充足**、**保证一人一单**、**原子性扣减库存与下单**、**异步下单入库** 等环节，主要逻辑在 `OrderService` 或 `SeckillVoucherService` 中实现。

### 5.4.1 接口层：接收秒杀请求

秒杀请求一般通过一个高速接口（如 `POST /vouchers/seckill/claim/{voucherId}`）由 `SeckillVoucherController` 接收，示例：
```
@PostMapping("/vouchers/seckill/claim/{voucherId}")
public Result seckillVoucher(@PathVariable Long voucherId) {
    return seckillVoucherService.seckillVoucher(voucherId);
}
```

### 5.4.2 服务层：秒杀校验与入队

在 `SeckillVoucherServiceImpl` 中，秒杀逻辑大致如下（伪代码）：
```
@Override
public Result seckillVoucher(Long voucherId) {
    // 1. 检查当前是否在秒杀时间窗口内
    LocalDateTime now = LocalDateTime.now();
    SeckillVoucher sv = seckillVoucherMapper.selectById(voucherId);
    if (now.isBefore(sv.getBeginTime()) || now.isAfter(sv.getEndTime())) {
        return Result.fail("秒杀尚未开始或已结束");
    }
    // 2. 判断库存（本地读取 Redis 预热库存）
    String stockKey = "seckill:stock:" + voucherId;
    Integer stock = Integer.valueOf(stringRedisTemplate.opsForValue()
                                 .get(stockKey));
    if (stock <= 0) {
        return Result.fail("库存不足");
    }
    // 3. 保证一人一单：利用 Redis Set 或者通过数据库唯一索引检查
    Long userId = UserHolder.getUser().getId();
    if (stringRedisTemplate.opsForSet().isMember("seckill:users:" + voucherId, userId)) {
        return Result.fail("您已参与过秒杀，不能重复下单");
    }
    // 将当前用户标记至 Set，防止重复下单
    stringRedisTemplate.opsForSet().add("seckill:users:" + voucherId, userId.toString());
    // 4. 扣减库存：使用 Redis 原子操作或 Lua 脚本
    Long remain = stringRedisTemplate.opsForValue().decrement(stockKey);
    if (remain < 0) {
        // 扣减失败，恢复标记并返回失败
        stringRedisTemplate.opsForSet().remove("seckill:users:" + voucherId, userId.toString());
        return Result.fail("库存已售罄");
    }
    // 5. 生成全局唯一订单ID
    long orderId = redisIdWorker.nextId("order");
    // 6. 构建秒杀订单消息并投递到消息队列
    SeckillOrderMessage msg = new SeckillOrderMessage(orderId, userId, voucherId);
    rabbitTemplate.convertAndSend("seckill_exchange", "seckill.order", msg);
    return Result.ok(orderId); // 返回订单ID给前端
}
```

#### 5.4.2.1 校验秒杀时间窗口
秒杀券表中存储了 `begin_time` 与 `end_time`，先校验当前的 `LocalDateTime.now()` 是否在窗口内，否则直接返回“尚未开始或已结束”。

#### 5.4.2.2 判断并扣减库存
- **预热库存读取**：秒杀开始前已将库存数值缓存到 Redis 的 `seckill:stock:[voucherId]`，秒杀期间直接在 Redis 中读取减少数据库压力。
- **使用 Redis 原子递减**：`stringRedisTemplate.opsForValue().decrement(stockKey)` 会返回递减后的库存值，若 `< 0` 则说明库存已售罄，需要进行回滚操作（将用户从 Set 中移除），并返回抢购失败。
- **使用 Lua 脚本保证原子性**（可选）：也可以通过预编译 Lua 脚本一次性完成“判断库存 > 0 且 扣减库存 > 0”两步，从而避免多条命令带来的并发竞态。例如：
```
local stockKey = KEYS[1]
local usersKey = KEYS[2]
local userId = ARGV[1]
local voucherId = ARGV[2]
-- 1. 判断是否已下单
if redis.call("SISMEMBER", usersKey, userId) == 1 then
    return 2 -- 已下单
end
-- 2. 判断库存
if tonumber(redis.call("GET", stockKey)) <= 0 then
    return 0 -- 库存不足
end
-- 3. 扣减库存、记录下单用户
redis.call("DECR", stockKey)
redis.call("SADD", usersKey, userId)
return 1 -- 秒杀成功
```
然后在 Java 端用 `stringRedisTemplate.execute(luascript, Arrays.asList(stockKey, usersKey), userId.toString(), voucherId.toString())` 一次性调用，避免多次网络往返，提高效率且保证原子性。

#### 5.4.2.3 保证一人一单
- **Redis Set 方案**：如上所示，使用 `SISMEMBER seckill:users:[voucherId] userId` 判断用户是否已经抢过，若为 `1` 则拒绝下单；否则在扣减库存成功后，执行 `SADD seckill:users:[voucherId] userId` 标记该用户已抢购。
- **数据库唯一索引方案**：在 `tb_voucher_order` 表中，对 `(user_id, voucher_id)` 建立联合唯一索引，若同一用户再次插入同一秒杀券会因唯一索引违例而失败，需要捕捉异常并返回“重复下单”。

### 5.4.3 异步下单：消息队列处理

- **组织消息并投递**  
    当 Redis 校验通过后，不直接执行数据库写操作，而是将所需参数（`orderId`, `userId`, `voucherId`, `shopId` 等）封装成一个消息对象 `SeckillOrderMessage`，通过 `rabbitTemplate.convertAndSend("seckill_exchange", "seckill.order", msg)` 发往消息队列，立即返回抢单结果给前端。
    
- **异步消费者处理**  
    在另一个线程池或独立服务中，设置 RabbitMQ 的消费者监听队列 `seckill.order.queue`，收到消息后执行数据库写入：
```
@RabbitListener(queues = "seckill.order.queue")
public void handleSeckillOrder(SeckillOrderMessage msg) {
    Long orderId = msg.getOrderId();
    Long userId = msg.getUserId();
    Long voucherId = msg.getVoucherId();
    // 再次确认库存与一人一单（幂等性检查），以防网络抖动导致消息重复
    SeckillVoucher sv = seckillVoucherMapper.selectById(voucherId);
    if (sv.getStock() <= 0) {
        // 库存不足，直接丢弃或记录日志
        return;
    }
    // 尝试扣减库存（乐观锁或直接更新行锁）
    int updated = seckillVoucherMapper.decrementStockSql(voucherId);
    if (updated == 0) {
        // 扣减失败，说明库存不足
        return;
    }
    // 插入订单
    VoucherOrder order = new VoucherOrder();
    order.setId(orderId);
    order.setUserId(userId);
    order.setVoucherId(voucherId);
    order.setShopId(msg.getShopId());
    voucherOrderMapper.insert(order);
}
```

- **并发与幂等性**
    
    - 消息队列消费逻辑中需做好幂等性校验，避免同一个消息因为网络重试多次消费导致重复插入订单。一般会先判断 `tb_voucher_order` 表中是否已存在 `orderId`，若存在直接放弃插入。
    - 扣减库存的 SQL 示例：
```
<update id="decrementStockSql">
    UPDATE tb_seckill_voucher 
    SET stock = stock - 1 
    WHERE voucher_id = #{voucherId} AND stock > 0
</update>
```
通过 `AND stock > 0` 约束与返回更新行数来判断扣减是否成功，若返回 `1` 表示扣减成功，`0` 表示失败（库存不足）。

## 5.5 高并发下的优化与防护

秒杀高峰时，大量请求涌入可能导致 Redis、数据库或消息队列瞬时压力骤增。黑马点评项目通过以下手段进行优化与防护：

### 5.5.1 缓存预热与本地队列削峰

- **库存预热**：前文所述，提前将 `stock` 缓存到 Redis，秒杀过程中仅操作缓存；可利用本地 JVM 的 `BlockingQueue` 与单线程异步池先行接收秒杀请求，按速率限制（Rate Limiter）或定时批量将请求写入 Redis/消息队列，削平突发并发波动。

### 5.5.2 使用 Lua 脚本保证原子操作

- 将“判断库存 > 0、判断是否已下单、扣减库存、记录用户抢购标记”合并到一个 Lua 脚本中执行，避免网络抖动与并发条件下的中间态，减少 Redis 往返次数并提升原子性。示例如前文 4.2.2 所示。

### 5.5.3 消息队列与异步下单削峰

- 秒杀请求先写入 RabbitMQ 消息队列，Web 服务立即返回响应，减轻数据库写入压力；消费者端通过高性能线程池并行处理消息，速率可根据数据库性能进行适当配置，避免超卖与 DB 阻塞。

### 5.5.4 本地缓存（可选）

- 为更进一步提高并发吞吐量，可在应用级别引入**Caffeine**作为本地一阶缓存，将热点秒杀券信息（如活动开始/结束时间）缓存到本地内存，减少对 Redis 的访问频率，同时搭配 Redis 二级缓存实现三级缓存架构。此策略与商户查询场景类似，只不过针对秒杀券的元数据做读缓存。

### 5.5.5 一人一单的幂等性与一致性

- 在高并发下，单机 Redis Set 方案已具备基本防重效果，但在分布式环境可能存在网络抖动导致 Set 失效或消费者重复消费消息的情况。应结合**数据库唯一索引**对 `(user_id, voucher_id)` 进行约束，若插入失败则说明重复下单，需丢弃并记录日志，以保证幂等性。

## 5.6 异常场景与处理

- **库存超卖**
    
    - 若没有使用原子减库存操作，而是先查询再更新，可能出现并发读后写导致超卖。黑马点评项目通过 Redis 原子递减或数据库层面的乐观锁更新（`UPDATE ... WHERE stock > 0` 带条件）来避免超卖问题。
    
- **一人多单**
    
    - 在高并发条件下，两个并行请求都同时判定 Redis Set 中不存在该用户，此时两者都能够通过一人一单的判断并继续执行。为进一步保证可靠性，异步消费者会再检查数据库是否已经存在该 `(user_id, voucher_id)` 组合的订单，若存在则直接丢弃第二条消息，从而实现幂等处理。
    
- **消息丢失或重复**
    
    - RabbitMQ 在非持久化队列或网络抖动下可能出现消息丢失，为此应将队列与消息声明为持久化，并在生产者端开启消息确认（Publisher Confirms），消费者端开启手动 ACK，确保消息处理可靠。
    - 若存在重复投递，则通过异步消费时的幂等性校验（数据库唯一索引或Redis Set）来丢弃重复订单，防止重复写入。
    
- **Redis 宕机或网络抖动**
    
    - Redis 不可用时，秒杀接口应降级或拒绝请求，并返回“秒杀系统繁忙，请稍后重试”，以保护后台数据库不被集中打爆。此外，可设置本地内存限流或熔断策略，避免请求洪峰下游服务不可用。

## 5.7 典型代码示例

### 5.7.1 秒杀下单接口与 Service
```
@RestController
@RequestMapping("/vouchers/seckill")
public class SeckillVoucherController {
    @Autowired
    private SeckillVoucherService seckillVoucherService;

    @PostMapping("/claim/{voucherId}")
    public Result seckillVoucher(@PathVariable Long voucherId) {
        return seckillVoucherService.seckillVoucher(voucherId);
    }
}
```
```
@Service
public class SeckillVoucherServiceImpl implements SeckillVoucherService {
    @Autowired
    private SeckillVoucherMapper seckillVoucherMapper;
    @Autowired
    private StringRedisTemplate stringRedisTemplate;
    @Autowired
    private RedisIdWorker redisIdWorker;
    @Autowired
    private RabbitTemplate rabbitTemplate;

    @Override
    public Result seckillVoucher(Long voucherId) {
        // 1. 判断时间窗口
        SeckillVoucher sv = seckillVoucherMapper.selectById(voucherId);
        LocalDateTime now = LocalDateTime.now();
        if (now.isBefore(sv.getBeginTime()) || now.isAfter(sv.getEndTime())) {
            return Result.fail("秒杀尚未开始或已结束");
        }
        // 2. 预热库存读取
        String stockKey = "seckill:stock:" + voucherId;
        Integer stock = Integer.valueOf(stringRedisTemplate.opsForValue().get(stockKey));
        if (stock <= 0) {
            return Result.fail("库存不足");
        }
        // 3. 一人一单检查：Redis Set
        Long userId = UserHolder.getUser().getId();
        String usersKey = "seckill:users:" + voucherId;
        if (stringRedisTemplate.opsForSet().isMember(usersKey, userId.toString())) {
            return Result.fail("您已参与过秒杀，不能重复下单");
        }
        // 4. 扣减库存：Redis 原子递减
        Long remain = stringRedisTemplate.opsForValue().decrement(stockKey);
        if (remain < 0) {
            // 回滚用户标记
            stringRedisTemplate.opsForSet().remove(usersKey, userId.toString());
            return Result.fail("库存已售罄");
        }
        // 5. 标记用户已抢购
        stringRedisTemplate.opsForSet().add(usersKey, userId.toString());
        // 6. 生成订单ID并异步下单
        long orderId = redisIdWorker.nextId("order");
        SeckillOrderMessage msg = new SeckillOrderMessage(orderId, userId, voucherId, sv.getShopId());
        rabbitTemplate.convertAndSend("seckill_exchange", "seckill.order", msg);
        return Result.ok(orderId);
    }
}
```

### 5.7.2 异步消费者与数据库写入
```
@Service
public class SeckillOrderListener {
    @Autowired
    private SeckillVoucherMapper seckillVoucherMapper;
    @Autowired
    private VoucherOrderMapper voucherOrderMapper;

    @RabbitListener(queues = "seckill.order.queue")
    public void handleSeckillOrder(SeckillOrderMessage msg) {
        Long orderId = msg.getOrderId();
        Long userId = msg.getUserId();
        Long voucherId = msg.getVoucherId();
        // 幂等性检查：是否已下单
        if (voucherOrderMapper.selectCount(
                Wrappers.<VoucherOrder>lambdaQuery()
                        .eq(VoucherOrder::getUserId, userId)
                        .eq(VoucherOrder::getVoucherId, voucherId)) > 0) {
            return; // 已下单，丢弃重复消息
        }
        // 乐观锁扣库存
        int success = seckillVoucherMapper.decrementStockSql(voucherId);
        if (success == 0) {
            return; // 库存扣减失败，可能库存不足
        }
        // 写入订单
        VoucherOrder order = new VoucherOrder();
        order.setId(orderId);
        order.setUserId(userId);
        order.setVoucherId(voucherId);
        order.setShopId(msg.getShopId());
        voucherOrderMapper.insert(order);
    }
}
```

### 5.7.3 Lua 脚本示例
```
-- seckill.lua
local stockKey = "seckill:stock:" .. KEYS[1]
local usersKey = "seckill:users:" .. KEYS[1]
local userId = ARGV[1]
-- 判断是否已下单
if redis.call("SISMEMBER", usersKey, userId) == 1 then
    return 2
end
-- 判断库存是否充足
local stock = tonumber(redis.call("GET", stockKey))
if stock <= 0 then
    return 0
end
-- 扣减库存并标记用户
redis.call("DECR", stockKey)
redis.call("SADD", usersKey, userId)
return 1
```
在 Java 中执行：
```
DefaultRedisScript<Long> script = new DefaultRedisScript<>();
script.setScriptText(luaScriptContent);
script.setResultType(Long.class);
Long result = stringRedisTemplate.execute(
    script, Collections.singletonList(voucherId.toString()), userId.toString());
if (result == 0) {
    // 库存不足
} else if (result == 2) {
    // 重复下单
} else {
    // 秒杀成功，生成订单
}
```

## 5.8 流程图
![[黑马点评秒杀优惠券.svg]]

# 6 探店笔记与点赞

黑马点评的“探店笔记”与“点赞”功能是基于**Spring Boot**与**Redis**构建的，它们充分利用了Redis的高速读写特性来提升系统性能和用户体验。探店笔记（也称“达人探店”）允许用户发布图文并茂的笔记内容，并将图片先上传到服务器或云存储后插入笔记表；笔记数据保存在关系型数据库（如MySQL）的`tb_blog`表中，同时将热点笔记信息缓存在Redis以加速查询。点赞功能则依托Redis的**Set**集合来实现“用户点赞一次，再次点击取消点赞”的幂等性控制，并通过**ZSet**有序集合维护点赞排行榜，从而可以灵活地获取Top N点赞笔记。以下内容将分别从功能流程、数据库设计、后端实现、Redis模型以及前端交互等方面，详细介绍探店笔记与点赞功能的实现原理和关键技术点。

## 6.1 探店笔记功能

### 6.1.1 数据库设计

1. **`tb_blog` 表结构**
    
    - `id`（BIGINT）：主键，自增或由分布式ID生成器生成，唯一标识一篇探店笔记。
    - `user_id`（BIGINT）：发布笔记的用户ID，用于关联用户表，后续展示笔记作者信息。
    - `title`（VARCHAR）：探店笔记的标题，简要概括笔记内容。
    - `content`（TEXT）：笔记正文，包括文字、标签、餐厅信息等。
    - `images`（VARCHAR）：以逗号分隔或JSON数组形式存储笔记配图的文件名或URL，前端展示时拼接完整路径。
    - `liked`（INT）：点赞总数，用于快速排序或展示点赞数。
    - `created`（DATETIME）：笔记创建时间，方便展示发布时间及做分页查询。

2. **`tb_blog_comments` 表结构**
    
    - `id`（BIGINT）：主键，自增，标识一条评论。
    - `blog_id`（BIGINT）：外键，关联`tb_blog.id`，表示哪篇笔记的评论。
    - `user_id`（BIGINT）：发评论的用户ID。
    - `comment`（TEXT）：评论内容。
    - `created`（DATETIME）：评论时间。

3. **索引与优化**
    
    - `tb_blog` 常对`created`进行倒序排序，以便实现“最新笔记”的分页查询，因此对`created`和`liked`字段可以分别创建组合索引，优化分页性能。
    - 对`tb_blog.user_id`建立索引，方便查询某个用户的所有笔记。

### 6.1.2 图片上传与存储

1. **前端文件上传接口**
    
    - 在`UploadController`中，定义了一个`@PostMapping("/upload/blog")`接口，接收`MultipartFile`类型的图片文件。
    - 服务器端为图片生成唯一文件名（如使用UUID或时间戳+随机数），并调用`transferTo(new File(IMAGE_UPLOAD_DIR, fileName))`将图片保存到本地目录，`IMAGE_UPLOAD_DIR`通常在系统常量中定义，可根据实际环境修改，或将图片上传到阿里云OSS等云存储。[
    - 返回结果为图片文件名，前端接收到后将其保存在`images`字段的列表中。

2. **图片URL拼接**
    
    - 发布笔记时，将图片文件名集合拼接为逗号分隔的字符串存入`tb_blog.images`字段；展示时前端使用配置好的服务器域名前缀拼接图片路径，如`https://domain.com/images/{fileName}`。
    - 对于云存储方案，可直接将图片上传至OSS，并将OSS返回的URL数组存储到数据库；展示时直接使用完整URL。

### 6.1.3 发布探店笔记流程

1. **前端请求**
    
    - 用户点击“发布探店笔记”按钮，在表单中填写标题、内容及上传多张图片。
    - 前端首先调用图片上传接口，将每张`MultipartFile`上传至后端，后端存储后返回文件名列表；前端将这些文件名临时保存在数组。
    - 填写完毕点击“提交”，前端将`title`、`content`，以及用逗号拼接后的`images`字符串一起封装到`BlogDTO`对象，通过`@RequestBody`发送到`BlogController.publish`接口。

2. **后端接收并保存**
    
    - `BlogController.publish(@RequestBody BlogDTO blogDTO)`方法中，先利用`UserHolder.getUser().getId()`获取当前登录用户ID，并将其设置到`blogDTO.userId`。
    - 然后调用`blogService.publish(blogDTO)`，在`BlogServiceImpl`中，将`BlogDTO`转换为`Blog`实体（使用`BeanUtil.copyProperties`），并将`blog.setLiked(0)`、`blog.setCreated(LocalDateTime.now())`等属性补齐。
    - 最后调用`blogMapper.insert(blog)`将探店笔记写入`tb_blog`表，获取自增或生成的`blog.getId()`。

3. **返回结果**
    
    - 保存成功后，后端返回`Result.ok(blog.getId())`给前端，前端可跳转至探店笔记详情页或刷新当前列表。

### 6.1.4 查看探店笔记

1. **分页查询列表**
    
    - 前端请求`GET /blog/hot?page={currentPage}`接口（或类似路径），用于获取热点探店笔记列表。
    - 在`BlogController.queryHotBlog(Integer current)`方法中，通过`blogService.queryHotBlog(current)`实现分页查询。
    - `BlogServiceImpl.queryHotBlog`内部调用MyBatis-Plus的`query().orderByDesc("liked").page(new Page<>(current, MAX_PAGE_SIZE))`，按照点赞数倒序分页。
    - 随后对每条`Blog`记录调用`queryBlogUser(blog)`方法加载作者信息，并调用`isBlogLiked(blog)`判断当前登录用户是否已点赞（见后文点赞功能）。[
    - 将包含作者信息和`isLike`状态的`BlogDTO`列表返回给前端。

2. **详情查询**
    
    - 前端点击某条笔记后，调用`GET /blog/{id}`接口获取笔记详情。
    - `BlogController.queryById(@PathVariable Long id)`方法中，先获取`blogMapper.selectById(id)`获取`Blog`实体。
    - 将`Blog`与作者`UserDTO`（调用`queryBlogUser(blog)`)拼装，同时调用`isBlogLiked(blog)`判断点赞状态，并将包含笔记数据、作者信息、点赞数、点赞列表（如Top5点赞用户）等返回给前端。

## 6.2 点赞功能

### 6.2.1 功能需求与业务分析

1. **幂等性**
    
    - **需求**：同一个用户只能对同一篇笔记点赞一次；如果已经点赞，再次点击则取消点赞。
    - **挑战**：传统在数据库中直接对`liked`字段+1或-1会导致幂等性难以保障，造成重复点赞或无法取消点赞。
    
2. **性能与并发**
    
    - **需求**：点赞操作需要在高并发情况下依旧保持快速响应，避免每次点赞都访问数据库以减少压力。
    - **挑战**：热点笔记在短时间内可能会有成千上万的点赞请求，如果都写库，将对数据库造成巨大冲击，需要借助Redis的高并发写性能。
    
3. **排行榜**
    
    - **需求**：提供“点赞排行榜”功能，根据点赞时间或点赞数，查找Top N点赞用户或Top N热门笔记。
    - **实现思路**：利用Redis的**ZSet**有序集合，其Score可为点赞时间戳或递增值，实现对点赞时间或总点赞数排序，快速返回排行榜。

### 6.2.2 Redis 数据模型

1. **用户点赞状态：Set 集合**
    
    - 对每篇笔记（`blogId`）在Redis中维护一个Key为`blog:liked:{blogId}`的**Set**集合，该集合存储所有对这篇笔记点赞的用户ID。
    - 当用户`userId`点赞时，执行`SADD blog:liked:{blogId} userId`，如果返回1表示新增点赞，如果返回0表示已经存在、无需再次添加。
    - 当用户取消点赞时，执行`SREM blog:liked:{blogId} userId`，如果返回1表示移除成功。
    
2. **点赞总数：Hash 或 数据库字段同步**
    
    - 在数据库的`tb_blog.liked`字段用于记录点赞总数，同时会随每次点赞/取消操作而异步或同步更新该字段。
    - 也可以在Redis维护一个**Hash**，Key为`blog:counts`，field为`blogId`，value为当前点赞数量。每次`SADD`成功后执行`HINCRBY blog:counts {blogId} 1`，`SREM`成功后执行`HINCRBY blog:counts {blogId} -1`，以便快速获取总点赞数。
    
3. **点赞时间排序：ZSet 集合**
    
    - 如果要实现“最近点赞用户”或“最近点赞笔记”排行榜，可使用**ZSet**，Key为`blog:liked:time:{blogId}`，member为`userId`，score为当前时间戳（如毫秒）。
    - 执行`ZADD blog:liked:time:{blogId} {timestamp} {userId}`记录点赞时间；如果用户取消点赞则执行`ZREM blog:liked:time:{blogId} {userId}`并更新Hash中的点赞数或数据库字段。
    - 查询Top N点赞用户时，用`ZREVRANGE blog:liked:time:{blogId} 0 N-1`按时间倒序获取最近点赞用户列表。
    
4. **热门笔记排行：ZSet 集合**
    
    - 如果要获取“Top N热门笔记”，可使用Key为`blog:hot`的ZSet，member为`blogId`，score为当前点赞数（或点赞数+评论数等加权值）。
    - 笔记列表页面加载时优先从Redis的`ZREVRANGE blog:hot 0 N-1 WITHSCORES`获取热门笔记ID及点赞数，再批量从数据库或二级缓存加载完整笔记数据。

### 6.2.3 点赞接口与后端实现

#### 6.2.3.1 Controller 层

该接口接受`PUT /blog/like/{id}`请求，其中`id`为`blogId`。调用`blogService.likeBlog(id)`完成点赞或取消点赞逻辑。
```
@RestController
@RequestMapping("/blog")
public class BlogController {

    @Resource
    private IBlogService blogService;

    @PutMapping("/like/{id}")
    public Result likeBlog(@PathVariable("id") Long id) {
        return blogService.likeBlog(id);
    }
}
```

#### 6.2.3.2 Service 层

- 通过`isMember`判断用户是否已点赞，实现幂等性控制。
- 点赞时同时更新数据库`tb_blog.liked`字段和Redis Set、ZSet，保证点赞数数据库与缓存保持一致。
- 取消点赞时则执行相反操作，保证总是与数据库一致。
```
public class BlogServiceImpl extends ServiceImpl<BlogMapper, Blog> implements IBlogService {

    @Autowired
    private StringRedisTemplate stringRedisTemplate;

    @Override
    public Result likeBlog(Long id) {
        // 1. 获取当前用户ID
        Long userId = UserHolder.getUser().getId();
        // 2. Redis Set Key
        String key = "blog:liked:" + id;
        // 3. 判断用户是否已点赞
        Boolean isMember = stringRedisTemplate.opsForSet().isMember(key, userId.toString());
        if (Boolean.FALSE.equals(isMember)) {
            // 4. 未点赞，进行点赞操作
            //    4.1 数据库点赞数 +1
            update().setSql("liked = liked + 1").eq("id", id).update();
            //    4.2 Redis Set 添加用户
            stringRedisTemplate.opsForSet().add(key, userId.toString());
            //    4.3 更新 Redis Hash 或 ZSet（排行）等
            stringRedisTemplate.opsForZSet().incrementScore("blog:hot", id.toString(), 1);
        } else {
            // 5. 已点赞，进行取消点赞操作
            //    5.1 数据库点赞数 -1
            update().setSql("liked = liked - 1").eq("id", id).update();
            //    5.2 Redis Set 移除用户
            stringRedisTemplate.opsForSet().remove(key, userId.toString());
            //    5.3 更新 Redis ZSet（排行）
            stringRedisTemplate.opsForZSet().incrementScore("blog:hot", id.toString(), -1);
        }
        return Result.ok();
    }
}
```

#### 6.2.3.3 查询笔记时判断点赞状态

在`queryHotBlog`和`queryById`方法中调用该`isBlogLiked(blog)`方法，将`isLike`字段动态赋值给Blog或DTO，前端据此决定点赞按钮状态（是否高亮）。
```
private void isBlogLiked(Blog blog) {
    // 1. 获取当前用户ID
    Long userId = UserHolder.getUser().getId();
    if (userId == null) {
        return;
    }
    // 2. Redis Set Key
    String key = "blog:liked:" + blog.getId();
    // 3. 判断用户是否在该Set中
    Boolean isMember = stringRedisTemplate.opsForSet().isMember(key, userId.toString());
    // 4. 将结果赋值给 blog.setIsLike(...)
    blog.setIsLike(Boolean.TRUE.equals(isMember));
}
```

### 6.2.4 点赞排行榜

- **按点赞数排行**
    
    - 在Redis维护一个Key为`blog:hot`的ZSet，member为`blogId`，score为点赞总数。
    - 当需要获取“Top N热门探店笔记”时，用`ZREVRANGE blog:hot 0 N-1 WITHSCORES`快速返回前N名笔记ID及对应点赞数。
    - 根据返回的ID列表，批量从数据库加载`Blog`完整信息或从二级缓存（如Caffeine）读取，最后填充作者信息和点赞状态后返回给前端。
    
- **按点赞时间排行**
    
    - 若要展示“最近点赞用户”或“最近获得点赞的笔记”，可维护Key为`blog:liked:time:{blogId}`或全局`blog:liked:time`的ZSet，score为点赞时间戳。
    - 查询“Top N最近点赞”的用户：`ZREVRANGE blog:liked:time:{blogId} 0 N-1`；或者“Top N近期获得点赞的笔记”：`ZREVRANGE blog:liked:time 0 N-1`。
    - 此排名方式适用于“查看谁最近给该笔记点了赞”或“查看哪些笔记最近受到用户青睐”。

# 7 好友关注和feed流

好友关注（Follow）与Feed流（Timeline/News Feed）的实现，核心在于如何高效地将用户 A 的动态推送给其关注者 B，并且在高并发场景下保证系统可扩展性与实时性。通常会结合以下几种技术手段：

1. **关系型数据库设计** —— 维护用户关注/粉丝关系表（Follow 表）和动态内容表（例如 Blog、FeedItem 表）。
2. **拉模式（Pull Model）与推模式（Push Model）** —— 拉模式在用户查看 Feed 时再动态从数据库或缓存拉取所有关注用户的最新动态；推模式在用户发布动态时立即“推送”给所有粉丝，将内容写入各粉丝的个人 Feed 队列。
3. **缓存与消息队列** —— 针对热点用户（大V），通常采用消息队列（Kafka、RabbitMQ）做异步广播，再结合 Redis 列表（List）、有序集合（ZSet）或 Hash结构保存各用户的 Feed 缓存，减少数据库压力。
4. **混合策略** —— 对普通用户使用推模式快速下发，对粉丝量极大的用户（如明星、官方账号）则使用拉模式避免一条动态要写入成百万个粉丝 Feed 导致写放大。

## 7.1 数据库设计

### 7.1.1 用户表与动态表

1. **用户表（user）**  
    存储用户基本信息，包括用户ID（`id`）、昵称（`name`）、头像地址、注册时间等字段。
    
2. **动态表（feed_item / blog）**  
    存储用户发布的动态内容。常见字段有：
    - `feed_id`（BIGINT，主键）
    - `user_id`（BIGINT，发布者ID，外键关联 user.id）
    - `content`（TEXT 或 VARCHAR，动态文本/摘要）
    - `media`（VARCHAR，存放图片/视频 URL 列表，逗号分隔或 JSON 格式）
    - `created_time`（DATETIME，发布时间，用于排序）
    - 其他业务字段：点赞数（`likes`）、评论数（`comments`）等等。

### 7.1.2 关注关系表

**关注表（follow）**，存储用户之间的关注与粉丝关系，一般有以下设计：
```
CREATE TABLE follow (
    user_id      BIGINT NOT NULL,  -- 关注者 A 的用户ID
    follow_user  BIGINT NOT NULL,  -- 被关注者 B 的用户ID
    created_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (user_id, follow_user),
    INDEX idx_follow_user (follow_user),
    INDEX idx_user_id (user_id)
);
```
- **`user_id`**：发起关注的用户 A。
- **`follow_user`**：被关注的用户 B。
- **联合主键（`user_id`, `follow_user`）**：确保 A 不能重复关注同一 B。
- **索引**：为了高效查询 A 的关注列表（`WHERE user_id = A`）以及 B 的粉丝列表（`WHERE follow_user = B`）。

## 7.2 好友关注功能实现

### 7.2.1 关注/取关接口

1. **关注接口（Follow）**
- 首先检查关系表中是否已有记录，防止重复关注。
- 再向 `follow` 表中插入一行。
- 最后可将该关系写入 Redis Set：
    - **Key = `user:follow:{A}`**，Value 存所有 A 关注的用户 ID，方便“我关注了谁”的快速查询。
    - **Key = `user:fans:{B}`**，Value 存所有关注 B 的粉丝 ID，方便“谁关注了我”的查询。
```
@PostMapping("/user/{followUserId}/follow")
public Result followUser(@PathVariable Long followUserId) {
    Long currentUserId = UserHolder.getUser().getId();
    // 1. 判断是否已经关注，若已关注则直接返回
    int count = followMapper.selectCount(
        Wrappers.<Follow>lambdaQuery()
                .eq(Follow::getUserId, currentUserId)
                .eq(Follow::getFollowUser, followUserId));
    if (count > 0) {
        return Result.fail("已关注该用户");
    }
    // 2. 插入关注关系
    Follow follow = new Follow();
    follow.setUserId(currentUserId);
    follow.setFollowUser(followUserId);
    followMapper.insert(follow);
    // 3. （可选）添加到 Redis 中做缓存，如粉丝列表
    stringRedisTemplate.opsForSet()
       .add("user:follow:" + currentUserId, followUserId.toString());
    stringRedisTemplate.opsForSet()
       .add("user:fans:" + followUserId, currentUserId.toString());
    return Result.ok();
}
```

2. **取关接口（Unfollow）**
- 直接在 `follow` 表中删除对应记录。
- 并同步在 Redis Set 中移除关注关系。
```
@DeleteMapping("/user/{followUserId}/unfollow")
public Result unfollowUser(@PathVariable Long followUserId) {
    Long currentUserId = UserHolder.getUser().getId();
    // 1. 删除关注关系
    followMapper.delete(
        Wrappers.<Follow>lambdaQuery()
                .eq(Follow::getUserId, currentUserId)
                .eq(Follow::getFollowUser, followUserId));
    // 2. 从 Redis 中删除
    stringRedisTemplate.opsForSet()
       .remove("user:follow:" + currentUserId, followUserId.toString());
    stringRedisTemplate.opsForSet()
       .remove("user:fans:" + followUserId, currentUserId.toString());
    return Result.ok();
}
```

### 7.2.2 获取关注列表与粉丝列表

1. **获取关注列表**
    - 优先尝试从 Redis Set `user:follow:{A}` 取所有成员（Set members），若 Redis 缓存不存在或失效，再从数据库查询：
    - 这样做主要是为了后续快速获取 A 关注了哪些用户，做 Feed 拉取或好友推荐等。
```
Set<String> followSet = stringRedisTemplate.opsForSet()
                            .members("user:follow:" + A);
if (CollectionUtils.isEmpty(followSet)) {
    // 从数据库查询 A 关注的所有记录
    List<Follow> list = followMapper.selectList(
        Wrappers.<Follow>lambdaQuery()
                .eq(Follow::getUserId, A));
    // 将 B IDs 写入 Redis Set
    for (Follow f : list) {
        stringRedisTemplate.opsForSet()
            .add("user:follow:" + A, f.getFollowUser().toString());
    }
}
// 根据 followSet 查询对应 user 表获取昵称、头像等信息，拼装成 DTO 返回
```

2. **获取粉丝列表**
    - 类似获取关注列表，只需用 Redis Set `user:fans:{B}`。
    - Redis 失效则回落到数据库 `WHERE follow_user = B` 查询，再把结果写到 Redis。

## 7.3 Feed 流（新闻流）实现

好友关注之后，用户 A 无法直接从数据库加载所有关注人每条动态，因为关注人可能很多，拉取时会有 N+1 查询或过多联合排序的问题。常见思路有两种：

- **拉模式（Pull/On-Read）**
- **推模式（Push/On-Write）**
- **混合模式（Hybrid）**

### 7.3.1 拉模式（Pull Model）

#### 7.3.1.1 原理

- 当用户 B 打开自己的 Feed 页面时，再动态查询 B 关注的所有用户集合（取自 `user:follow:{B}`），
- 对这些用户 ID 列表，批量查询动态表 `feed_item`：
- B 的客户端拿到这 50 条动态后，进行分页或续页拉取。
```
SELECT * FROM feed_item
 WHERE user_id IN (list_of_follow_ids)
 ORDER BY created_time DESC
 LIMIT 0, 50;
```

#### 7.3.1.2 优缺点

- **优点**
    
    - 写操作简单：A 只需写入自己的动态表 `feed_item`，无需额外推送给粉丝。
    - 没有写放大：不管 A 有多少粉丝，都只做一次写操作。
    
- **缺点**
    
    - 每次 B 拉取时，需要对多个关注人 ID 做 `IN` 查询并排序，随着关注人数增多，查询开销急剧增大。
    - 如果某些用户同时关注了数千人，拉取最新 Feed 可能变成一次大 `JOIN` 或子查询，造成慢查询。
    

#### 7.3.1.3 适用场景

- 用户关注人数较少或媒体动态量级不高的场景。
- 对实时性要求不严格，例如偶尔刷新一次即可。

### 7.3.2 推模式（Push Model）

#### 7.3.2.1 原理

- 当用户 A 发布一条动态后，系统会读取 A 的所有粉丝列表（可以从 Redis Set `user:fans:{A}` 获取）并将这条动态复制（写入）到每个粉丝 B 的个人 Feed 队列中。
- 每个粉丝 B 拥有一个在线或离线的 Feed 队列：常见做法是使用 Redis List 或 ZSet，Key 类似 `feed:inbox:{B}`。
    
    - **Redis List**（时间倒序入队，浏览时做 `LRANGE 0,49`）
    - **Redis ZSet**（Score 为动态时间戳，浏览时做 `ZREVRANGE 0,49`）
    
- A 发布流程示例（伪代码）：
```
public void publishFeed(FeedItem feedItem) {
    // 1. 写入动态表（持久化）
    feedItemMapper.insert(feedItem);
    // 2. 获取 A 的所有粉丝 ID
    Set<String> fans = stringRedisTemplate.opsForSet()
                       .members("user:fans:" + feedItem.getUserId());
    // 3. 将 feedItem 序列化后推送给每个粉丝的 Redis 队列
    for (String fanId : fans) {
        String key = "feed:inbox:" + fanId;
        // 使用 ZSet 可以按时间排序，List 则只能按插入顺序
        stringRedisTemplate.opsForZSet()
           .add(key, JSON.toJSONString(feedItem), feedItem.getCreatedTime().getTime());
        // 同时可设置一个红线长度，保证最新 N 条动态，例如只保留最先 1000 条
        stringRedisTemplate.opsForZSet()
           .removeRange(key, 0, -1001);
    }
}
```
- 粉丝 B 查看自己的 Feed 时，只需从 Redis ZSet `feed:inbox:{B}` 取最新若干条：
```
Set<String> feedJsons = stringRedisTemplate.opsForZSet()
                         .reverseRange("feed:inbox:" + B, 0, 49);
```

#### 7.3.2.2 优缺点

- **优点**
    
    - B 查看 Feed 时非常快，仅需 O(log N) 或 O(1) 从 Redis 中获取最新 N 条，无需数据库再做排序。
    - 实时性高，用户可以几乎秒级看到 A 的新动态。
    
- **缺点**
    
    - 写放大（Fan‐out on write）：如果 A 有上百万粉丝，则每发一条动态，都要对上百万个列表做写入操作，可能造成 Redis 宕机或写延迟。
    - 对大V（粉丝很多的用户）不适合，需要额外限流或改为拉模式。

#### 7.3.2.3 处理大V粉丝问题

1. **限流/异步消费**
    
    - A 发布动态后，将其发布请求先写入消息队列（Kafka、RabbitMQ）中，快速返回给 A。再由后台异步消费者读取消息并批量推送到 Redis，利用多线程并发或分片来减少峰值压力。
    
2. **混合模式**
    
    - 针对大V账号，改为拉模式：即 A 的动态只写入 `feed_item` 表，不再写入每个粉丝的 Redis 队列。粉丝在拉取时，将同时从 Redis（部分普通关注者的队列）和数据库（大V的动态）两处拉取，合并排序后展示。
    - 这样 A 发一条动态只做一次写库，不做百万级的写 Redis；B 在拉取时多做一次拉库查询，牺牲少量实时性换取系统稳定性。

### 7.3.3 混合模式（Hybrid Model）

最常见的实战做法是把大多数普通用户动态走推模式（Push），而对极少数粉丝量超大用户（大V）走拉模式（Pull）。

- 在 A 发布动态时，先判断 A 的粉丝数量是否超过某个阈值（如 10000）。
    - 若 **未超过**：走推模式，把动态写入所有粉丝的 Redis 队列。
    - 若 **超过**：只写入数据库，不在 Redis 中批量推送；粉丝会在拉取时把大V的动态拉过来。

这种做法能够兼顾实时性与可扩展性：普通用户下发延迟极低，大V不造成 Redis 写压力，也不会影响普通用户。

## 7.4 数据存储与缓存策略

### 7.4.1 Redis 数据结构设计

1. **关注关系缓存（Set）**
    
    - **Key = `user:follow:{A}`**
        - Value = Set（A 关注的所有用户 ID）
    - **Key = `user:fans:{B}`**
        - Value = Set（关注 B 的所有用户 ID）
    
2. **Feed 队列（List 或 ZSet）**
    
    - **Key = `feed:inbox:{B}`**
        
        - 如果使用 List: 新动态 `LPUSH`，读取时 `LRANGE 0,N-1`，确保倒序最新在前。
        - 如果使用 ZSet: 新动态 `ZADD score=timestamp`，读取时 `ZREVRANGE 0,N-1`。
        
    - ZSet 的优点是可以中间删、也可以按 Score 做分页；List 的优点是操作更简单、FIFO/ LIFO 特性直观。
    
3. **热门用户/热门动态（可选）**
    
    - **Key = `feed:hot_users`**（ZSet）
        - 存储用户 ID，Score 为粉丝数或活跃度，方便推荐。
    - **Key = `feed:hot_items`**（ZSet）
        - 存储 feedItemId，Score 可为点赞数+评论数+发布时长加权得分，方便推荐热门动态。

### 7.4.2 持久化存储

1. **动态表（feed_item）**
    
    - 所有动态首先写入数据库，以便持久化。常见字段：`feed_id`、`user_id`、`content`、`media`、`created_time`。
    - 可以对 `user_id`、`created_time` 建联合索引，方便按时间倒序拉取指定某个或多个用户的历史动态。
    
2. **异步写 Redis**
    
    - 推荐使用消息队列解耦：A 发布后，第一步入库，第二步写 MQ 消息，返回给 A；后台消费者异步读取 MQ，将动态写 Redis。这样可以避免因 Redis 短暂故障导致 A 侧请求阻塞。
    
3. **冷数据归档**
    
    - 超过某一天、一个月的历史动态可以归档到冷库（如 Hadoop、ElasticSearch、Object Storage），从 Redis/关系库迁移到大数据平台或搜索引擎，降低主库负载。

## 7.5 实现示例流程

以纯推模式为例，结合 Spring Boot + MyBatis-Plus + Redis，给出一个简化的流程示例。

### 7.5.1 发布动态（Push）
```
@Service
public class FeedService {

    @Autowired
    private FeedItemMapper feedItemMapper;    // MyBatis-Plus Mapper

    @Autowired
    private FollowMapper followMapper;        // 查询粉丝列表

    @Autowired
    private StringRedisTemplate redisTemplate;

    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;  // 用于异步推送

    // 1. 源代码：用户发布动态
    public void publishFeed(Long userId, String content, List<String> mediaUrls) {
        // 1.1 写入 DB
        FeedItem feed = new FeedItem();
        feed.setUserId(userId);
        feed.setContent(content);
        feed.setMedia(String.join(",", mediaUrls));
        feed.setCreatedTime(LocalDateTime.now());
        feedItemMapper.insert(feed);

        // 1.2 发送消息到 Kafka 异步广播
        FeedMessage msg = new FeedMessage();
        msg.setFeedId(feed.getFeedId());
        msg.setUserId(userId);
        msg.setCreatedTime(feed.getCreatedTime());
        kafkaTemplate.send("feed-topic", JSON.toJSONString(msg));
    }
}
```

### 7.5.2 异步消费者（Async Push）
```
@Service
public class FeedConsumer {

    @Autowired
    private StringRedisTemplate redisTemplate;

    @Autowired
    private FollowMapper followMapper;

    // 2. Kafka 消费者方法
    @KafkaListener(topics = "feed-topic", groupId = "feed-group")
    public void handleFeedMessage(String msgJson) {
        FeedMessage msg = JSON.parseObject(msgJson, FeedMessage.class);
        Long authorId = msg.getUserId();

        // 2.1 从 DB 或 msg 中获取 feedItem 对象
        //    如果消息中信息足够，可以直接用 msg 中的 feedId + timestamp；否则再从 DB load
        FeedItem feed = new FeedItem();
        feed.setFeedId(msg.getFeedId());
        feed.setUserId(authorId);
        feed.setCreatedTime(msg.getCreatedTime());

        // 2.2 获取作者所有活跃粉丝
        Set<String> fanIds = redisTemplate.opsForSet()
                                .members("user:fans:" + authorId);
        if (CollectionUtils.isEmpty(fanIds)) {
            // 如果 Redis 中不存在，需要从数据库拉取一次并写入 Redis
            List<Follow> fans = followMapper.selectList(
                Wrappers.<Follow>lambdaQuery()
                        .eq(Follow::getFollowUser, authorId));
            fanIds = fans.stream()
                         .map(f -> f.getUserId().toString())
                         .collect(Collectors.toSet());
            if (!fanIds.isEmpty()) {
                redisTemplate.opsForSet()
                    .add("user:fans:" + authorId, fanIds.toArray(new String[0]));
            }
        }

        // 2.3 推送给每个粉丝的 Redis ZSet 队列
        for (String fanId : fanIds) {
            String key = "feed:inbox:" + fanId;
            // Score 用时间戳，便于倒序获取
            redisTemplate.opsForZSet()
                .add(key, JSON.toJSONString(feed), 
                     feed.getCreatedTime().toEpochSecond(ZoneOffset.UTC));
            // 保持队列长度，只保留最新 N 条，避免内存无限增长
            redisTemplate.opsForZSet().removeRange(key, 0, -1001);
        }
    }
}
```

### 7.5.3 用户查看自己的Feed
```
@RestController
@RequestMapping("/feed")
public class FeedController {

    @Autowired
    private StringRedisTemplate redisTemplate;

    @GetMapping("/timeline")
    public Result getTimeline(@RequestParam(defaultValue = "0") Long cursor,
                              @RequestParam(defaultValue = "20") int limit) {
        Long userId = UserHolder.getUser().getId();
        String key = "feed:inbox:" + userId;

        // 3.1 使用 ZREVRANGE 带分数（cursor 表示上次拉取的时间戳）
        //    实现类似 Redis 的 ZREVRANGEBYSCORE 支持滚动分页
        Set<ZSetOperations.TypedTuple<String>> tuples = redisTemplate.opsForZSet()
            .reverseRangeByScoreWithScores(key, cursor == 0 ? Double.POSITIVE_INFINITY : cursor,
                                           0, 0, limit);
        if (CollectionUtils.isEmpty(tuples)) {
            return Result.ok(Collections.emptyList());
        }

        // 3.2 解析结果
        List<FeedItemDTO> feedList = new ArrayList<>();
        long nextCursor = 0;
        int count = 0;
        for (ZSetOperations.TypedTuple<String> t : tuples) {
            String feedJson = t.getValue();
            double score = t.getScore();  // 时间戳
            FeedItem feed = JSON.parseObject(feedJson, FeedItem.class);
            FeedItemDTO dto = new FeedItemDTO(feed);
            feedList.add(dto);

            // 记录最小的 score 作为 nextCursor
            if (count == 0 || score < nextCursor) {
                nextCursor = (long) score;
            }
            count++;
        }
        // 3.3 返回 DTO 列表和 cursor
        Map<String, Object> res = new HashMap<>();
        res.put("feeds", feedList);
        res.put("nextCursor", nextCursor);
        return Result.ok(res);
    }
}
```
**解释**：
- `cursor` 初始传 `0` 表示取最新的所有。
- Redis ZSet 中 `score` 存储的即为 `createdTime` （Unix 时间戳）。
- 使用 `reverseRangeByScoreWithScores(key, from, to, offset, count)` 实现时间倒序分页拉取。
- 通过返回的最小 timestamp 作为下一次分页的 `cursor`，实现滑动分页。

## 7.6 性能优化与防护

### 7.6.1 针对普通用户的小规模关注

- 对绝大多数普通用户，其粉丝数在几百甚至更少，写一条动态时推送到几百个队列是可承受的，且能极大提高 B 拉取的速度。
- 因此默认对粉丝数小于某个阈值（如 5000）的账号走推模式。

### 7.6.2 针对大V的大量粉丝

- **混合模式**：粉丝数超过阈值时，把 A 的动态放到一个单独的“热点”列表，粉丝拉取时与普通 Redis 队列合并：
    1. A 发布时：只写入 `feed_item` 数据库，不推送给 100w 粉丝 Redis 队列
    2. 粉丝 B 拉取时：
        - 先从自己的 “feed:inbox:{B}” 取普通关注者推送的动态
        - 再从数据库查询大V的最新几条动态：
            `SELECT * FROM feed_item   WHERE user_id IN (list_of_bigV_ids)  AND created_time < lastCursor  ORDER BY created_time DESC  LIMIT limit -已取数量;`
        - 然后合并两个来源的列表、按时间排序后返回给前端。

### 7.6.3 缓存雪崩与热点防护

1. **批量预热**
    
    - 定期（如每日、每小时）将热门用户的粉丝列表和热门动态预热到 Redis，避免大批用户同时访问时缓存未命中导致 DB 瞬时压力大。
        
2. **TTL 随机化**
    
    - 如果对 Feed 队列也设置了过期（如缓存超过 30 天自动清理），需要在 TTL 上加随机抖动，避免大批键同一时刻过期造成缓存雪崩。
        
3. **本地缓存二级**
    
    - 对于经常拉取的小规模 Feed（如仅取最新 10 条），可以在应用层使用 Caffeine 做一级缓存，拉取频率极高的用户先从本地缓存中读取；过期时再回到 Redis。

### 7.6.4 后台任务与冷数据清理

- **定期清理过期 Feed**：定期触发任务清理 Redis 中超过 60 天（或其他时长）的 Feed 队列，避免 Redis 内存无限增长。
- **归档历史动态**：将 1 年以上的旧动态迁移到冷库（如 Elasticsearch、Hadoop），从而减少主数据库表大小与 Redis 存储量。

### 7.6.5 数据库分表与分库

- 当用户量达到千万级别时，单个 `follow` 表与 `feed_item` 表会非常庞大，需要对这两张表做分表或分库：
    
    - **Follow 表分库分表**：根据 `user_id` 做哈希分表；粉丝数较大的大V需要额外单独存储；
    - **FeedItem 表分库分表**：根据 `user_id` 或时间做分表，以缩小单张表的大小并加快查询。
    
- 分表后在拉取大V动态时，可能要跨分表合并，需要做多路查询并在应用层合并排序。

# 8 用户签到

## 8.1 BitMap 数据结构简介

- **BitMap**（位图）在 Redis 中利用一个二进制位（bit）表示某个实体（如用户）在某一天是否执行过签到操作：`1` 表示已签到，`0` 表示未签到。相比传统关系型数据库中的表记录方式，BitMap 只需要用一个比特位存储一个签到状态，极大地节约内存，而像“连续签到天数”这种统计只需要一次性读取多位二进制数据即可完成。
- 在 Redis 中，BitMap 相关操作主要包括 `SETBIT key offset value`、`GETBIT key offset`，以及 `BITFIELD key GET/SET/...` 等。
    - `SETBIT key offset 1`：将 key 对应的位图在指定的偏移量（offset，以天数或某个序号为单位）处置为 `1`，表示当天或当天序号已签到。
    - `GETBIT key offset`：获取 BitMap 指定位置处的值。
    - `BITFIELD key GET u<width> 0`：一次性从位图最右侧（低位）获取指定宽度（`width`）的无符号整数，可用于计算连续签到天数等。

## 8.2 签到功能的核心流程

1. **获取当前用户与日期信息**
    
    - 从 `UserHolder`（或 Session）中获取当前登录用户的 ID、昵称等信息。
    - 使用 `LocalDateTime now = LocalDateTime.now();` 获取当前年月日信息，并将年月切分为 `yyyy/MM` 格式，方便按月统计。
    
2. **拼接 Redis Key**
    
    - 按月来统计用户签到信息，例如 `USER_SIGN_KEY + nickname + '_' + userId + '_' + yyyy/MM`，如 `sign:张三_1001_2025/06`。
    - 该 Key 对应的 BitMap 的第 0 位表示当月 1 号，第 1 位表示当月 2 号，…，第 `day-1` 位表示当月第 `day` 号。
    
3. **签到（打卡）操作：SETBIT**
    
    - 获取当天日期 `int day = now.getDayOfMonth();`，然后调用：
        `stringRedisTemplate.opsForValue().setBit(key, day - 1, true);`
    - 该操作将当天的 BitMap 对应位置设为 `1`，表示用户当天已签到。
    - 示例代码：
```
public Result sign() {
    UserDTO user = UserHolder.getUser();
    LocalDateTime now = LocalDateTime.now();
    String keySuffix = now.format(DateTimeFormatter.ofPattern("yyyy/MM"));
    String key = USER_SIGN_KEY + user.getNickName() + "_" + user.getId() + "_" + keySuffix;
    int day = now.getDayOfMonth();
    stringRedisTemplate.opsForValue().setBit(key, day - 1, true);
    return Result.ok();
}
```

4. **连续签到天数统计：BITFIELD + 二进制计算**
    
    - 要统计本月截至今天的连续签到天数，需要先获取从 BitMap 最低位（当月第 1 号）开始，宽度为 `day` 的一个无符号二进制数
    - 该返回值 `result.get(0)` 即为一个十进制数，表示从当月 1 号到当月 `day` 号的二进制向量，如 `1011110…`（最低位对应第 1 号）。
    - 通过不断右移并判断最低位是否为 `1`，即可累计连续 `1` 的个数，从而得到“连续签到天数”：
    - 整体流程（摘自 turn0search1）：
        
        1. 拼接 key，同上。
        2. 通过 `BITFIELD` 一次性读取截止当天的十进制值。
        3. 从最低位开始，通过循环 `while ((num & 1) == 1)` 累加连续 `1` 的个数，直到遇到 `0` 停止。  
    
5. **统计当月签到总天数：BITCOUNT**
    
    - 如果需要统计本月一共签到多少天，只需直接调用 Redis 的 `BITCOUNT key` 命令，返回 BitMap 中 `1` 的个数：
    - 该操作由 Redis 底层遍历位图并统计 `1` 的数量，时间复杂度与字节数（位图长度）成正比，依然远优于关系型数据库逐行扫描统计。[
    
6. **示例：查询当天是否已签到**
    
    - 读取 BitMap 指定偏移量的值：
        `Boolean isSignedToday = stringRedisTemplate.opsForValue().getBit(key, day - 1);`
    - 如果 `isSignedToday == true`，说明用户当日已签到；否则未签到。


## 8.3 后端完整示例
```
@Service
public class UserServiceImpl implements IUserService {

    @Autowired
    private StringRedisTemplate stringRedisTemplate;

    private static final String USER_SIGN_KEY = "sign:user:";

    @Override
    public Result sign() {
        // 1. 获取当前登录用户
        UserDTO user = UserHolder.getUser();
        // 2. 获取当前日期
        LocalDateTime now = LocalDateTime.now();
        // 3. 拼接业务 Key：sign:user:nickName_userId_yyyy/MM
        String keySuffix = now.format(DateTimeFormatter.ofPattern("yyyy/MM"));
        String key = USER_SIGN_KEY + user.getNickName() + "_" + user.getId() + "_" + keySuffix;
        // 4. 获取当前是当月第几天
        int day = now.getDayOfMonth();
        // 5. 使用 SETBIT 设置当天签到状态
        stringRedisTemplate.opsForValue().setBit(key, day - 1, true);
        return Result.ok();
    }

    @Override
    public int getConsecutiveSignCount() {
        UserDTO user = UserHolder.getUser();
        LocalDateTime now = LocalDateTime.now();
        String keySuffix = now.format(DateTimeFormatter.ofPattern("yyyy/MM"));
        String key = USER_SIGN_KEY + user.getNickName() + "_" + user.getId() + "_" + keySuffix;
        int day = now.getDayOfMonth();
        // 获取当前月到今天的签到二进制数
        List<Long> result = stringRedisTemplate.opsForValue()
            .bitField(key, BitFieldSubCommands.create()
                .get(BitFieldSubCommands.BitFieldType.unsigned(day))
                .valueAt(0));
        if (result == null || result.isEmpty()) {
            return 0;
        }
        long num = result.get(0);
        int count = 0;
        // 从二进制最低位开始统计连续 1 的个数
        while ((num & 1) == 1) {
            count++;
            num >>= 1;
        }
        return count;
    }

    @Override
    public long getMonthlySignCount() {
        UserDTO user = UserHolder.getUser();
        LocalDateTime now = LocalDateTime.now();
        String keySuffix = now.format(DateTimeFormatter.ofPattern("yyyy/MM"));
        String key = USER_SIGN_KEY + user.getNickName() + "_" + user.getId() + "_" + keySuffix;
        // 统计当月位图中 1 的个数
        return stringRedisTemplate.execute((RedisCallback<Long>) connection ->
            connection.bitCount(key.getBytes()));
    }
}
```

# 9 UV 统计

## 9.1 HyperLogLog (HLL) 数据结构简介

- **HyperLogLog**（HLL）是一种近似算法，用来统计极大量元素去重之后的基数（即集合大小），其内存开销常量为 12 KB 左右，无论元素数量如何增长都不会再增大，误差率约为 0.81%。因此，若要统计一天内或一段时间内的去重访客数量，HLL 能在保证低内存占用的前提下完成大规模去重计数。

- 在 Redis 中，HyperLogLog 通过命令 `PFADD key element [element ...]` 向 HLL 中添加一个或多个元素（一般以用户 ID 或 IP 地址作为唯一标识）；再通过 `PFCOUNT key` 获取估算的基数（即独立访客数）；若要合并多个 HLL，可以使用 `PFMERGE destkey sourcekey [sourcekey ...]`。

## 9.2 UV 统计的典型场景

1. **博客/商铺页面访问 UV**
    
    - 当用户访问某个博客详情页或商铺详情页时，后端在处理该请求的同时可以调用 `PFADD uv:blog:blogId userId` 或 `PFADD uv:shop:shopId userId`，将用户 ID 添加到对应 Page 的 HLL 中。
    - 在需要展示 UV 数据时，调用 `PFCOUNT uv:blog:blogId` 获得该博客当天／累计的独立访客数。[
    
2. **网站整体 UV**
    
    - 可在用户访问首页或任意页面时，将用户 ID 添加至 `PFADD uv:website:yyyy/MM/dd userId`，按天统计，或者使用 `PFADD uv:website:global userId` 统计总 UV。
    - 若要将多日 UV 合并统计，可调用 `PFMERGE uv:website:week:yyyyWW uv:website:yyyy/MM/dd1 uv:website:yyyy/MM/dd2 …` 形成周统计，再通过 `PFCOUNT` 得到去重后的一周 UV。

## 9.3 后端实现流程

1. **在访问拦截器或 Controller 中添加 HLL**
    
    - 在 `BlogController.queryById(@PathVariable Long id)` 或 `ShopController.queryById(@PathVariable Long id)` 中，在返回页面内容之前，执行
    - 这样，无论同一用户当天访问多少次该页面，都只会被 HLL 计为 1 次，避免重复。
```
// 获取当前登录用户 ID
Long userId = UserHolder.getUser().getId();
// 获取当天日期，例如 2025/06/03
LocalDate today = LocalDate.now();
String redisKey = "uv:blog:" + id + ":" + today.format(DateTimeFormatter.ofPattern("yyyy/MM/dd"));
// 将 userId 添加到 HLL
stringRedisTemplate.opsForHyperLogLog().add(redisKey, userId.toString());
```

2. **获取并展示 UV 统计值**
    
    - 当需要获取某个博客当日 UV 时，调用：
        `String redisKey = "uv:blog:" + id + ":" + today.format(DateTimeFormatter.ofPattern("yyyy/MM/dd")); Long uvCount = stringRedisTemplate.opsForHyperLogLog().size(redisKey);`
    - 该 `uvCount` 为当天访问该博客的独立用户数（近似值）。
    - 如果需要获取累计或多日 UV，可使用 `PFCOUNT` 或先 `PFMERGE` 多个键再 `PFCOUNT`（示例见下文）。
    
3. **示例代码**
```
@GetMapping("/blog/{id}")
public Result queryById(@PathVariable Long id) {
    // 1. 统计 UV（独立访客）
    UserDTO user = UserHolder.getUser();
    if (user != null) {
        LocalDate today = LocalDate.now();
        String uvKey = "uv:blog:" + id + ":" + today.format(DateTimeFormatter.ofPattern("yyyy/MM/dd"));
        stringRedisTemplate.opsForHyperLogLog().add(uvKey, user.getId().toString());
    }

    // 2. 从数据库获取博客详情
    Blog blog = blogService.getById(id);
    if (blog == null) {
        return Result.fail("博客不存在");
    }

    // 3. 将详情封装为 DTO 并返回
    BlogDTO dto = BeanUtil.copyProperties(blog, BlogDTO.class);
    // 可附加作者信息和 UV 统计
    String uvKeyToday = "uv:blog:" + id + ":" + LocalDate.now().format(DateTimeFormatter.ofPattern("yyyy/MM/dd"));
    Long todayUv = stringRedisTemplate.opsForHyperLogLog().size(uvKeyToday);
    dto.setTodayUv(todayUv);
    return Result.ok(dto);
}
```


## 9.4 合并多日 UV 统计

- 若要获取某段时间（如一周、一月）的 UV，须先将对应日期的 HLL 合并，然后再取基数。例如，计算一周的 UV：
- 合并后，如果不再需要该 HLL，可以调用 `stringRedisTemplate.delete(weekKey)` 清理，以节省内存。
```
// 假设要统计 2025 年第23周的 UV
List<String> dailyKeys = Arrays.asList(
    "uv:blog:" + id + ":2025/06/02",
    "uv:blog:" + id + ":2025/06/03",
    "uv:blog:" + id + ":2025/06/04",
    "uv:blog:" + id + ":2025/06/05",
    "uv:blog:" + id + ":2025/06/06",
    "uv:blog:" + id + ":2025/06/07",
    "uv:blog:" + id + ":2025/06/08"
);
String weekKey = "uv:blog:" + id + ":2025:week:23";
// 合并 HLL
stringRedisTemplate.opsForHyperLogLog().merge(weekKey, dailyKeys.toArray(new String[0]));
// 再取基数
Long weekUv = stringRedisTemplate.opsForHyperLogLog().size(weekKey);
```

## 9.5 其他实现细节与优化

### 9.5.1 Redis Key 设计与过期策略

1. **Key 命名规范**
    
    - 签到 BitMap：`sign:user:{userId}:{yyyy/MM}`
    - 当日 UV：`uv:blog:{blogId}:{yyyy/MM/dd}` 或 `uv:shop:{shopId}:{yyyy/MM/dd}`
    - 累计/多日 UV：如 `uv:blog:{blogId}:week:{yyyyWW}`、`uv:blog:{blogId}:month:{yyyyMM}` 等
    - 通过采用 `:` 分隔，能够在运维或阶段性统计时方便批量按前缀清理或查询。
    
2. **过期时间设置**
    
    - 签到 BitMap：按月统计，一个月结束后，下个月初可设置上月 BitMap 过期，TTL = 当月剩余秒数 + 一天。
    - UV 当日 Key：可设置在第二天凌晨过期，TTL = 次日零点 timestamp − 现在 timestamp。
    - 对于周/月维度的合并 UV Key，可在统计完成后立即删除或设置短 TTL。

### 9.5.2 内存与性能考量

1. **BitMap 大小**
    
    - 按月生成的 BitMap 至多需要 31 位（当月天数），一个 BitMap 对象底层占用 `(31 / 8 = 4)` 个字节，对应 Redis 底层字符串为 1 个或多个字节，因此非常轻量。即便有几百万用户在线打卡，也只会占用几 MB 内存。
    
2. **HLL 内存占用**
    
    - 每个 HyperLogLog 对象固定占用约 12 KB。若要为每篇博客或商铺都维护一个 HLL，这在数据量巨大时也会占用较多内存。因此，一般只对热门博客或热门商铺单独维护 HLL；对于其他较少访问的页面，可按天合并到项目级别的“UV:website”中，或考虑使用更小粒度（如按小时）再合并。
    
3. **复制与合并开销**
    
    - `PFMERGE` 会将多个源 HLL 压缩合并到目标 HLL，消耗 CPU 与网络带宽，建议在统计峰值较低或利用定时任务（如夜间）执行合并，而非在请求高峰期直接进行。
    - 对于“实时 UV”需求，可先在业务逻辑中仅 `PFADD`，而在业务监控或统计侧（如 Grafana/Jenkins 定时脚本）合并后再获取结果，以避免对线上 Redis 造成过大压力。

### 9.5.3 事务与并发

- 签到写入 BitMap 与统计连续签到均为单个 Redis 原子操作，不需要显式事务；
- UV 统计仅是 `PFADD`、`PFCOUNT`、`PFMERGE`，各自命令原子执行；JVM 层面可将 `opsForHyperLogLog().add` 和后续业务逻辑放入同一个 Service 事务中，但 Redis 操作本身无需事务。