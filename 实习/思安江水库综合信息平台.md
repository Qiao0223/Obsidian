# 1. 业务需求
## 1.1. 平台定位与总体目标

该系统称为“思安江水库综合信息平台”，基于 RuoYi 快速开发框架，定位于**水库（大坝）全生命周期管理**。其主要目标是为水库管理单位提供：

- **实时监测与数据采集**：自动化采集水位、雨量、流量等环境数据，并支持多时段（即时、日/月/年、旬/历史）查询与可视化；
- **预警与阈值管理**：对水位、雨量、流量等关键指标进行阈值配置，自动生成报警记录并向运维人员推送；
- **设备与档案管理**：维护测量设备台账、工程档案（图纸、报告）、维护与巡检记录，确保信息可追溯；
- **运维与应急**：支持日常维护计划与隐患上报、巡检计划与记录，以及应急预案和洪水防汛操作方案管理；
- **业务流程与审批**：提供“业务办公数据库结构”之类的业务办公流程，从发起、一级审批、二级审批到结束，满足内部协同需求；
- **绩效考核**：基于“千分制”模型，对巡检、维护等任务进行量化打分与统计；
- **移动端支撑**：通过 `/app` 系列接口，为手机端推送任务列表、报警、设备数据曲线、考核列表等；
- **系统管理与扩展**：依托 RuoYi 的用户/角色/菜单/权限体系，开放 SMS、微信支付、代码生成、简单流程引擎等公共能力。

## 1.2. 核心业务功能

### 1. 数据采集与监测

- **多源数据**：雨量（小时/日/旬/月/历史）、水位、流量等；
- **可视化曲线**：按日、月、年维度绘制数据趋势图；
### 2. 报警与阈值

- **阈值配置**：管理员可配置各类指标上下限；
- **自动报警**：生成水位报警、雨量报警、流量报警记录；
- **报警记录查询与导出**；

### 3. 设备与档案

- **设备台账**：类型、分类、指标、型号等；
- **档案管理**：大坝档案（DamArchive）、工程图纸（DamEngineeringDrawing）、报告（DamReport）；
- **文件导出**：支持 Excel 导入/导出以便离线归档；

### 4. 维护、巡检与应急

- **维护计划**：年度计划、到期提醒；
- **隐患上报**：维护问题（MaintenanceIssue）登记与跟踪；
- **巡检流程**：巡检计划与巡检记录（PatrolPlan/PatrolRecords）；
- **应急预案与防汛方案**：EmergencyResponsePlan、FloodControlOperationPlan；

### 5. 业务办公流程

- **“业务办公数据库结构”流程**：多级审批（发起 → 一级审批 → 二级审批 → 结束），包括强制驳回、备注、状态流转；
- **审批角色管理**：可配置首/二级审批人，并通过 Web/API 进行审批操作；

### 6. 绩效考核

- **千分制模型**：ThousandthCategory、ThousandthProject、ThousandthIndicator、ThousandthScoreRecord 等；
- **考核列表与详情**：提供分页查询及明细展示；

### 7. 移动端支持

- **统一 App 接口**：`/app` 前缀下一站式获取任务列表、报警、设备数据、考核信息等；
- **消息推送**：SysAppMessage 服务支持移动端消息通知；

## 1.3. 支撑与公共能力

- **系统管理**：基于 RuoYi 的用户/角色/菜单/字典/部门/区域管理，保障权限与组织架构管理；
- **短信与支付**：SMS 配置、模版与发送记录；
- **代码生成**：`hslt-generator` 模块提供表结构到前后端代码的自动化生成；
- **简单流程引擎**：`hslt-flow` 模块（SimpleFlowDefine、Task、Work）支持自定义轻量级业务流；
- **公共库**：`hslt-common` 模块封装分页、注解、工具类（Token、Date、Excel 等）与统一异常处理；

# 2. 项目模块

项目是一个基于 Maven 的多模块工程，共包含以下子模块：hslt-admin、hslt-framework、hslt-system、hslt-quartz、hslt-generator、hslt-common、hslt-care、hslt-flow、hslt-dam、hslt-sync 和 hslt-sms 。下面针对每个模块简要说明其职责：

- **hslt-admin**：  
    提供系统的 Web 后台管理入口，是一个 Spring Boot 应用。包含核心启动类 `ReservoirManageApplication` 和部署支持类 `ReservoirManageInitializer`，以及面向前端的各类 REST 控制器（如业务数据查询、用户登录、APP 接口等） 。
    
- **hslt-framework**：  
    核心框架层，定义公共的控制器基类、统一返回结果（`AjaxResult`、`TableDataInfo`）、分页与树形结构支持、全局异常处理、Swagger 配置等基础设施，为上层模块（如 admin、system）提供底层支撑 。
    
- **hslt-system**：  
    系统功能模块，承载用户管理、部门/岗位管理、菜单与权限分配、字典维护、参数配置、通知公告、日志审计、在线用户监控、服务与缓存监控等系统级功能。通常以 `com.hslt.system` 包名组织业务代码，提供完整的 CRUD 接口与后台管理支撑 。
    
- **hslt-quartz**：  
    定时任务模块，封装 Quartz 调度框架，包含调度配置类 `ScheduleConfig`、作业执行工具类（如 `CronUtils`、`ScheduleUtils`）、并提供 `SysJobController`、`SysJobLogController` 等管理接口，用于动态增删改查定时任务及其执行日志 。
    
- **hslt-generator**：  
    代码生成器模块，通过数据库表结构动态生成 Java 实体、Mapper、Service、Controller 以及前端页面（Vue、API 调用），底层基于 Velocity 模板实现，极大提升 CRUD 开发效率 。
    
- **hslt-common**：  
    通用工具模块，提供全局常量、注解（如 `@DataScope`、`@RepeatSubmit`）、自定义异常（`BaseException`、`UtilException`、文件/用户异常等）、XSS 校验、可重读请求过滤器、Redis 缓存实现、ID 生成工具、Excel 导入导出、微信支付支持、通用 JSON 处理等基础组件 。
    
- **hslt-flow**：  
    简易流程管理模块，支持流程定义与执行，包含 `SimpleFlowController`、`SimpleFlowDefineController`、`SimpleFlowTaskController`、`SimpleFlowWorkController` 等，用于构建轻量级工作流或审批流 。
    
- **hslt-dam**：  
    大坝监测数据模块，负责大坝安全监测相关数据的存储与查询，包括雨量、流量、水位等实时与历史数据实体（如 `DataRainfallCollection`、`DataFlowRateCollection`、`DataWaterLevelCollection`）、设备与告警记录、应急预案等领域模型及对应的 DAO/Service 层 。
    
- **hslt-sync**：  
    数据同步模块，提供多源数据采集（如 GNSS、实体机数据、CF3、第三方监测平台等）的定时拉取与入库功能，通过一系列 `DataCollector` 实现自动同步外部监测数据 。
    
- **hslt-sms**：  
    短信服务模块，封装阿里云与腾讯云 SMS 接口，提供 `SmsService` 接口及模板 `AliyunSmsTemplate`、`TencentSmsTemplate` 实现，用于系统内验证码、告警与通知短信发送 。

# 3. 雨量业务

## 3.1. 实时数据采集

- 定时或实时接收、存储各监测点的原始降雨量读数
- 支持多种接入方式（多厂商传感器），并统一记录设备ID、采集时间、采集值及单位
- 提供接口可按时间范围或设备维度查询最新或历史原始数据

## 3.2. 多粒度历史数据管理

- **小时级**、**日级**、**旬级（十天）**、**月级**、**年级**多维度历史归档
- 系统按粒度定期汇总原始数据并存入对应的历史表，以便高效查询与统计
- 支持分页查看各粒度下的历史数据，满足灵活检索需求

## 3.3. 统计汇总与报表

- **滑动窗口统计**：自动计算过去 1、4、8、12、24 小时的累计降雨量
- **固定周期汇总**：根据年、季、月、旬等周期，汇总各监测点或全网的降雨总量
- **设备分组比对**：可按传感器分组，对比各组的累计、最大、最小值及发生时间
- **层级报表**：在统一查询界面，支持按年—季—月三级联动展示统计结果
- **动态实时值**：当期周期尚未结束时，自动追加“当前已记录最大/最小值”数据

## 3.4. 阈值告警

- 根据预设上下限阈值，对单点或汇总后的降雨量进行超高/偏低告警
- 支持对告警事件的产生时间、持续时长、处理状态进行记录与查询
- 提供告警列表、告警详情及历史告警统计功能，方便运维人员监控和复盘

## 3.5. 数据导出与报表模板

- 提供一键导出：任意粒度的原始或统计数据均可生成 Excel 报表
- 内置多套模板：日常列表导出模板与年度汇编/专题报表模板
- 导出文件自动填充：包括标题、统计区间、汇总表格及图例占位，交付给运营或管理端

### 整体流程概览

1. **采集** → 2. **分粒度归档** → 3. **滑动与周期统计** → 4. **阈值监测与告警** → 5. **报表导出**

- 全流程闭环，既满足实时监控，也支持历史审计与多维度分析。
- 既能灵活查询单点数据，也能开展全网或分组的综合报表。

## 3.6. UML活动图
![[mysql_flow.svg]]

# 4. 实时数据采集

## 4.1. 传感器

雨量传感器每一小时固定上传一次雨量数据，当5分钟内的雨量超过0.5mm触发一次数据上传，上传时将数据构造为JSON，通过 HTTP 将 JSON 串发送到后端，无上传失败重传机制，会丢失数据。

## 4.2. Controller 接收请求

```
@RestController
@RequestMapping("/dam/rainFallCollection")
public class DataRainfallCollectionController {
  @PostMapping
  public RequestResult add(@RequestBody DataRainfallCollection dataRainfallCollection) {
    return toResult(dataRainfallCollectionService.insertDataRainfallCollection(dataRainfallCollection));
  }
}
```

## 4.3. Service 写库（业务层）

```
@Service
public class DataRainfallCollectionServiceImpl implements IDataRainfallCollectionService {
  @Override
  @Transactional
  public int insertDataRainfallCollection(DataRainfallCollection data) {
    if (data == null) {
      throw new ServiceException("参数不合法！");
    }
    // 1) 写入 MySQL
    int count = dataRainfallCollectionMapper.insertDataRainfallCollection(data);
    // 2) Redis 缓存分支（代码中已注释，可按需开启）
    // insertRainDataToRedisCache(data.getDeviceId(), data);
    return count;
  }
  // … insertRainDataToRedisCache 方法实现 …
}
```

## 4.4. Mapper 接口

```
public interface DataRainfallCollectionMapper {
  int insertDataRainfallCollection(DataRainfallCollection dataRainfallCollection);
}
```

## 4.5. Redis 缓存分支

```
private void insertRainDataToRedisCache(Long deviceId, DataRainfallCollection data) {
  String key = "Rainfall:Stats:" + deviceId + ":" + DateUtils.format(data.getCollectionTime(), "yyyyMMdd");
  // 1) HINCRBY 累加当日总雨量  
  // 2) HSETNX 记录首次最小值；HMAX 更新最大值  
  // 3) (可选) 设置过期时间为 2 天  
}
```

该分支负责维护当天的“总降雨量／最大／最小”统计，读取 Redis 中现有值并原子更新，支持实时统计。

# 5. 多粒度历史数据管理

## 5.1. Quartz 调度 task

Quartz读取`sys_job`表中的任务配置，每日零点05分执行日、旬、月、年的聚合任务，错过触发立即重试，同一个JobDetail(任务)同时刻只能执行一个，按顺序执行

## 5.2. 聚合方法

日聚合方法先得到当前日期前一天的日期，再用前一天的日期查询`data_rainfall_collection`表统计出总雨量、最大时段雨量、最大时段雨量采集时间、最小时段雨量、最小时段雨量采集时间插入`data_rainfall_collection_day_historical`表中。

旬聚合方法先得到当前日期前一天的日期，再得到前一天日期所在的旬（上旬，中旬或下旬），确定统计时段的起始和终止时间，根据起止时间去原始记录表中查询统计并插入到旬降雨量表中。

月聚合方法先得到当前日期前一天的日期，再得到前一天日期所在的月，根据月份去原始记录表中查询统计并插入到月降雨量表中。

年聚合方法先得到当前日期前一天的日期，再得到前一天日期所在的年，根据年去原始记录表中查询统计并插入到年降雨量表中。

## 5.3. 幂等性

日降雨量统计表中，将设备id和日期作为唯一索引，插入时由数据库保证唯一。

旬降雨量统计表中，由于旬降雨记录表中的记录每一天都在发生变化，没办法用采集时间（当前旬时间最晚一条记录的下一天的零点）作为唯一索引，因此新增一个字段，当前旬的开始日期，相同的旬开始日期相同，将旬和设备id作为唯一索引，并且用ON DUPLICATE KEY UPDATE语句来更新记录，唯一索引冲突是更新数据来保证幂等。

月降雨量表同旬降雨量表。

年降雨量表同旬降雨量表。

## 5.4. 任务执行失败处理

Quartz 任务内部一旦抛出异常，并不会自动重试或补偿，而是由框架统一捕获并记录日志，后续按原定计划继续下次调度，具体流程如下

- **异常捕获**  
    所有定时任务最终都走进了 `AbstractQuartzJob.execute(...)`：
    由这一层的 `catch` 块拦截业务代码抛出的任何异常，不会向上抛出给调度器，也就不会触发 Quartz 的重试机制 。
    
- **失败日志记录**  
    在 `after(context, sysJob, e)` 中，无论成功还是失败，都会向数据库表 `sys_job_log` 写一条日志：
    - 如果参数 `e != null`，则设置 `status = FAIL`，并将异常堆栈摘要存入 `exception_info` 字段；
    - 否则 `status = SUCCESS`。  
        这样运维人员可以在管理后台查看失败记录，并根据日志内容做人工排查和重跑 。
    
- **不做自动重试**  
    – Quartz 内部的 MisfirePolicy（错过触发策略）仅针对“调度器在计划时间点未能触发”这类调度层面的误失（如停机、线程池繁忙），与任务内部抛出的异常无关 。  
    – 任务抛异常后，Quartz 会按原有的 Cron 表达式，在下一次计划时间重新触发，而不会重试“刚才那次失败的执行”。
    
- **手动补偿 & 运维**  
    – 如果需要对“失败的这次”做重试，系统提供了在管理界面或通过 API 的“立即执行”/“重跑”功能，可以手动触发该 JobDetail；  
    – 也可根据 `sys_job_log` 中的失败记录，编写额外的补偿脚本或使用 Spring Retry 在业务层插入自动重试逻辑。

# 6. 滑动窗口雨量统计

## 6.1. 需求描述

- **多时段粒度**

    - 系统支持预设时段：最近 1 h、3 h、6 h、12 h、24 h、48 h、72 h。

- **子区间拆分**

    - 对每个目标时段，将它等分为 N 个子区间（例如 12 个），按固定时长滑动：
        - 例如 24 h 时段拆成 12 段，每段 2 h；
        - 6 h 时段拆成 12 段，每段 30 min。
    - 每个子区间要分别计算降雨量（子区间降雨）。

- **累积总量**

    - 除了每个子区间的降雨，还要动态计算从该时段起始到本子区间末端的**累积降雨量**，用于叠加展示。
    - 子区间降雨以柱状显示，总累积降雨以折线叠加。

- **多维查询**

    - **按设备**：选择单个雨量站（deviceId）查看它在各子区间的降雨与累积；
    - **全网平均**：对所有在线设备取平均值，展示“全站平均子区间降雨”及“平均累积雨量”曲线。

## 6.2. 实现方式

- **建表 & 配置保留策略**  

对每台设备，一条 TimeSeries，打上 `deviceId` 标签，并设置保留（Retention）为比如 7 天：
```
TS.CREATE rainfall:<deviceId> \
  RETENTION 604800000 \
  LABELS deviceId <deviceId>
```
- `RETENTION` 单位毫秒，`604800000 = 7*24*3600*1000`。
- 标签 `deviceId` 方便跨设备聚合。

- **实时写入**  

每当来了一个新的采集点（五分钟或其他频率）：
```
TS.ADD rainfall:<deviceId> * <value>
```
`*` 让 Redis 用当前时间戳，`<value>` 是降雨量（mm）。

- **子区间聚合**  

比如要查询最近 P 小时，拆成 N 段，每段时长
```
bucketMs = P*3600*1000 / N
```
对单设备：
```
TS.RANGE rainfall:<deviceId> \
  FROM (NOW - P*3600000) TO NOW \
  AGGREGATION sum bucketMs
```
结果是 N 个数据点，每点是一个子区间的降雨总量。

- **累积曲线**  

后端也可以用 TimeSeries pipeline 做一次前缀和，但通常让前端算更灵活
```
// 假设 vals = [v1, v2, …, vN]
const cum = [];
vals.reduce((s, v, i) => (cum[i] = s + v, s + v), 0);
```

- **全设备平均**  

一次拉所有设备的子区间：
```
TS.MRANGE \
  FROM (NOW - P*3600000) TO NOW \
  FILTER deviceId=* \
  AGGREGATION sum bucketMs
```
它会返回多条 time-series（每个 deviceId 一条、都有 N 个点）。客户端把相同索引的 N 路值做平均，即得“全网平均子区间降雨”。

# 7. 传感器雨量超出预警值后实时告警

完整流程可以分为以下几个阶段：客户端“订阅”→服务器“维持”→业务逻辑“触发”→客户端“接收”

当传感器上传数据先写入redis和数据库，写入后判断是否到达告警值，若触发告警值写入告警记录表，然后调用告警controller中的push方法，将构造好的告警消息发送给当前所有在线用户。

## 7.1. 客户端建立 SSE 连接（订阅阶段）

1. 在页面初始化时，JS 通过 `EventSource` 发起一个对 `/dam/alerts/stream` 的 GET 请求
```
const evtSrc = new EventSource('/dam/alerts/stream');
```
2. 浏览器发送 HTTP 请求，并在请求头中自动携带 `Accept: text/event-stream`。
3. 服务器端的 `AlertSseController.streamAlerts()` 被调用，返回一个永不超时（`Long.MAX_VALUE`）的 `SseEmitter`：
    - 设置响应头 `Content-Type: text/event-stream;charset=UTF-8`
    - 连接保持打开，浏览器会一直等待服务器“推流”内容。
4. 控制器将这个 `SseEmitter` 存入内存列表 `emitters`，并在连接完成或超时时自动移除，防止内存泄漏。

## 7.2. 服务器维持连接（持久阶段）

- 自此，服务器端和客户端之间保持一个长连接（chunked encoding），浏览器处于“等待”状态。
- 可选：定期发送心跳（如 `emitter.send("\n")`）以防中间代理超时。

## 7.3. 业务逻辑触发告警（触发阶段）

某处业务代码（如 `RainAlarmRecordsServiceImpl.insertRainAlarmRecord`）往数据库插入一条新的告警记录：
```
int rows = rainAlarmRecordsMapper.insert(record);
if (rows == 1) {
    // 准备要推送的内容
    Map<String,Object> payload = Map.of(
        "type", "rain",
        "time", record.getAlarmTime(),
        "level", record.getAlarmLevel(),
        "message", record.getMessage()
    );
    alertSseController.publishAlert(payload);
}
```

`publishAlert(payload)` 遍历所有当前活跃的 `SseEmitter`：
```
for (SseEmitter emitter : emitters) {
    try {
        emitter.send(
          SseEmitter.event()
                    .name("alert")
                    .data(payload)
        );
    } catch (IOException ex) {
        emitters.remove(emitter);
    }
}
```

Spring 底层将上述事件序列化为标准 SSE 格式：
```
event: alert
data: {"type":"rain","time":"2025-05-27T18:30:00","level":"HIGH",...}
```
并 “push” 到客户端的 HTTP 流中。

## 7.4. 客户端接收并处理

浏览器内的 `EventSource` 连接一旦检测到新数据，就触发对应事件回调：
```
evtSrc.addEventListener('alert', e => {
  const alertData = JSON.parse(e.data);
  // 比如弹一个 toast
  showToast(`告警：${alertData.message}（${alertData.level}）`);
});
```

如果网络中断或服务端主动关闭连接，`evtSrc.onerror` 会被调用，浏览器会自动尝试重连：
```
evtSrc.onerror = () => {
  console.warn('SSE 断开，正在重连…');
};
```

重连时，浏览器会每隔几秒重新发起对同一 URL 的请求，整个流程重复。