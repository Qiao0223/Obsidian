# 1. 主从复制
## 1.1. 原理

Redis 的主从复制过程主要包括以下三个阶段：
### 1. 建立连接

- 从节点通过发送 `SLAVEOF` 或 `REPLICAOF` 命令，指定主节点的 IP 和端口，发起复制请求。
- 主从节点之间建立 TCP 连接，并进行身份验证（如果配置了密码）。

### 2. 数据同步

数据同步分为全量复制和部分复制两种方式：

#### 全量复制

适用于初次连接或无法进行部分复制的情况。

- 主节点执行 `BGSAVE` 命令，生成 RDB 快照文件。
- 主节点将 RDB 文件发送给从节点，从节点加载该文件，完成数据同步。
- 在 RDB 文件传输期间，主节点会将新的写命令缓存在复制积压缓冲区（Replication Backlog）中。
- RDB 文件加载完成后，主节点将缓冲区中的写命令发送给从节点，确保数据一致。

#### 部分复制

适用于网络中断后重新连接的情况。

- 从节点发送 `PSYNC` 命令，附带上次复制的偏移量。
- 如果主节点的复制积压缓冲区中仍保留有从节点缺失的数据，则只需发送这部分数据，实现增量同步。
- 如果缓冲区中没有所需数据，则退回到全量复制。
### 3. 命令传播

数据同步完成后，主节点会将新的写命令实时发送给从节点，从节点执行这些命令，保持数据一致性。

## 1.2. 主从复制的作用

- **数据冗余**：提供数据的热备份，增强系统的容灾能力。
- **故障恢复**：主节点故障时，从节点可接替服务，减少系统停机时间。
- **负载均衡**：通过读写分离，主节点处理写请求，从节点处理读请求，提高系统的并发处理能力。
- **高可用基础**：主从复制是实现 Redis 哨兵模式和集群模式的基础。

## 1.3. 注意事项

- **复制延迟**：由于网络延迟和异步复制，从节点的数据可能略滞后于主节点。
- **复制积压缓冲区大小**：默认大小为 1MB，可通过 `repl-backlog-size` 参数调整，以减少全量复制的频率。
- **从节点只读**：默认情况下，从节点为只读模式，避免数据不一致。
- **主从链路**：支持级联复制，即从节点也可以作为其他从节点的主节点。

# 2. 哨兵

Redis Sentinel 是一种高可用性解决方案，运行在特殊模式的 Redis 实例上，不支持读写，仅负责监控、故障检测、选举领导者、自动故障转移以及客户端配置提供[掘金](https://juejin.cn/post/6998564627525140494)[知乎专栏](https://zhuanlan.zhihu.com/p/516715720?utm_source=chatgpt.com)。Sentinel 通过流言协议传播监控信息，使用周期性的 INFO 和 PING 检测节点状态，并在主节点无响应后通过主观下线与法定人数投票确认客观下线，再通过 Raft-like 算法选举 Leader 并执行故障转移状态机，最后将新主节点信息提供给客户端并发出通知，同时建议将 Sentinel 部署为奇数节点以避免脑裂。
## 2.1. 监控 (Monitoring)

### 节点状态获取 (INFO)

Sentinel 启动后会向主节点发送 `INFO replication` 命令，定期（默认每 10s）拉取当前集群拓扑和复制状态，以发现新增或下线的从节点并更新监控列表。

### 心跳检测 (PING)

在与每个被监控节点建立 TCP 连接后，Sentinel 会每秒发送 `PING` 命令，若在配置的 `down-after-milliseconds` 时间内未收到回应，就标记为主观下线（SDOWN）状态。

## 2.2. 故障检测 (Failure Detection)

### 主观下线 (SDOWN)

当 Sentinel 发现与某个 Redis 实例的心跳连接断开或响应超时时，它会立刻将该实例标记为主观下线（`+sdown`），包括主节点、从节点或其他 Sentinel 本身均可被标记。

### 客观下线 (ODOWN)

一旦单个 Sentinel 标记 SDOWN，它会通过 `SENTINEL is-master-down-by-addr` 命令向其他 Sentinel 发起投票，收集下线确认；当下线票数达到大多数并且不小于配置项 `quorum` 时，即标记为客观下线（`+odown`）。这一过程确保只有在多数 Sentinel 一致认为主节点不可用时才会触发后续操作，从而降低误判风险。

## 2.3. Leader 选举 (Leader Election)

确定主节点客观下线后，Sentinel 会启动 Raft-like 的投票流程，以在发起故障转移的 Sentinel 中选出 Leader。只有被多数 Sentinel 选举为 Leader 的节点才有资格执行后续故障转移操作。这一选举流程符合 Raft 算法原则，确保同一时间仅有一个 Leader 进行故障转移，避免并发冲突与数据不一致。

## 2.4. 故障转移流程 (Failover Execution)

Leader Sentinel 进入故障转移状态机，由 `sentinelFailoverStateMachineZ` 函数管理，包括五个阶段：

1. **WAIT_START**：等待成为 Leader；
2. **SELECT_SLAVE**：从符合条件的从节点中选择优先级最高且复制偏移量最大的候选者；
3. **SEND_SLAVEOF_NOONE**：对候选从节点发送 `REPLICAOF NO ONE`，将其提升为新主节点；
4. **WAIT_PROMOTION**：等待节点完成主节点切换；
5. **RECONF_SLAVES**：将其余从节点重配置为跟随新主节点。  
    整体流程与 CSDN 博客中的四步监控-通知-故障转移-配置提供模型相吻合。

## 2.5. 客户端配置提供 (Configuration Provider)

故障转移完成后，Sentinel 集群通过 `SENTINEL get-master-addr-by-name <master-name>` 等命令向客户端提供最新的主节点地址；客户端应在初始化或故障转移后轮询或订阅 Sentinel，以实现主库连接的无缝切换。

# 3. Gossip 协议与集群发现

Sentinel 实例间通过 Redis 的发布/订阅机制在 `__sentinel__:hello` 频道上相互发现与通信，每隔 2s 发布带有自身 runId、监控主节点信息的 hello 消息，确保集群内所有 Sentinel 节点保持最新的成员与监控状态视图。

以上机制共同构成了 Redis Sentinel 的高可用保障：监控、故障检测、Leader 选举、自动故障转移与客户端通知，以及通过流言协议和投票协议确保分布式一致性与容错能力。

# 4. 集群

## 4.1. 特性
### 1. 数据分片（Sharding）

Redis 集群将整个键空间划分为 16384 个哈希槽（hash slot），每个键通过 CRC16 校验后对 16384 取模，确定其所属的槽位。每个节点负责管理其中的一部分槽位，从而实现数据的分布式存储。

### 2. 多主多从架构

集群中的每个主节点（master）可以有一个或多个从节点（slave）作为副本。主节点负责处理写请求，从节点则用于故障转移和读请求的负载均衡。

### 3. 自动故障转移

当某个主节点发生故障时，集群会自动将其从节点提升为新的主节点，并更新集群的槽位分配信息，确保服务的持续可用性。

### 4. 客户端直连与智能路由

客户端可以连接到集群中的任意节点，节点会根据请求的键计算其槽位，并将请求路由到负责该槽位的节点。如果客户端连接的节点不负责该键的槽位，会返回 MOVED 或 ASK 重定向指令，指导客户端重新发送请求。

## 4.2. 优点

- **高可用性**：支持主从复制和自动故障转移，确保服务的持续可用性。
- **可扩展性**：通过增加节点，可以线性扩展集群的存储容量和处理能力。
- **分布式存储**：数据分片机制使得数据分布在多个节点上，避免了单点瓶颈。

## 4.3. 限制

- **多键操作限制**：仅支持所有键位于同一槽位的多键操作，跨槽位的操作需要特殊处理。
- **事务支持有限**：事务操作仅限于同一槽位内的键，跨槽位的事务操作不被支持。
- **客户端复杂性**：客户端需要实现槽位映射和重定向处理，增加了开发复杂性。